{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_pickle from ./data_parameter/player_gaussin_fit/grid_custom_no_tokens/player10_gaussin_prob_grid_custom_no_tokens.pkl\n",
      "load_pickle from ./data_parameter/player_gaussin_fit/grid_custom_no_tokens/player10_gaussin_prob_grid_custom_no_tokens.pkl\n",
      "load_pickle from ./data_parameter/player_gaussin_fit/grid_custom_tokens/player10_gaussin_prob_grid_custom_tokens.pkl\n"
     ]
    }
   ],
   "source": [
    "import init_load_board\n",
    "exec(open('init_load_board.py').read())\n",
    "\n",
    "import init_simple_mdp\n",
    "exec(open('init_simple_mdp.py').read())\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import function_board as fb \n",
    "import function_tool as ft\n",
    "import function_get_aiming_grid \n",
    "exec(open('function_get_aiming_grid.py').read())\n",
    "\n",
    "import evaluate_score_probability_with_error as esp\n",
    "import function_solve_dp\n",
    "\n",
    "#%%\n",
    "data_parameter_dir = fb.data_parameter_dir\n",
    "result_dir = './result'       \n",
    "\n",
    "a_throw_list = []\n",
    "a_token_list = []\n",
    "\n",
    "for a in actions:\n",
    "    a_throw_list.append(a)\n",
    "\n",
    "for a in token_actions:\n",
    "    a_token_list.append(a)\n",
    "\n",
    "a_list = a_throw_list + a_token_list\n",
    "throw_num = len(a_throw_list)\n",
    "\n",
    "name_pa = 'player{}'.format(10)\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import function_board as fb\n",
    "import function_tool as ft\n",
    "import function_get_aiming_grid\n",
    "import function_evaluate_policy as fep\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(linewidth=300)\n",
    "np.set_printoptions(threshold=300)\n",
    "\n",
    "import torch\n",
    "torch.set_printoptions(precision=4)\n",
    "torch.set_printoptions(linewidth=300)\n",
    "torch.set_printoptions(threshold=300)\n",
    "\n",
    "[aiming_grid, prob_grid_normalscore, prob_grid_singlescore, prob_grid_doublescore, prob_grid_triplescore, prob_grid_bullscore] = function_get_aiming_grid.load_aiming_grid(name_pa, data_parameter_dir=data_parameter_dir, grid_version='custom_no_tokens')\n",
    "\n",
    "[aiming_grid, prob_grid_normalscore_nt, prob_grid_singlescore_nt, prob_grid_doublescore_nt, prob_grid_triplescore_nt, prob_grid_bullscore_nt] = function_get_aiming_grid.load_aiming_grid(name_pa, data_parameter_dir=data_parameter_dir, grid_version='custom_no_tokens')\n",
    "[aiming_grid, prob_grid_normalscore_t, prob_grid_singlescore_t, prob_grid_doublescore_t, prob_grid_triplescore_t, prob_grid_bullscore_t] = function_get_aiming_grid.load_aiming_grid(name_pa, data_parameter_dir=data_parameter_dir, grid_version='custom_tokens')\n",
    "\n",
    "import function_solve_dp_tokens as fsdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #prob_notbust\n",
    "# prob_notbust = np.zeros(len(prob_grid_normalscore_nt[:,0]))\n",
    "# prob_notbust[:throw_num] += prob_grid_normalscore_nt[:throw_num,0:4+1].sum(axis=1)\n",
    "# prob_notbust[:throw_num] += prob_grid_normalscore_t[throw_num:,0:4+1].sum(axis=1)\n",
    "\n",
    "# prob_notbust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_turn_transit_probability_nt(score_state, state_action, prob_normalscore, prob_doublescore, prob_bullscore):\n",
    "    \"\"\"\n",
    "    Solve the state transition probability after a turn playing with a specified aiming policy\n",
    "    \n",
    "    Args: \n",
    "        score_state: score at the beginning of the turn, e.g., 2,3,...,501 \n",
    "        state_action: a dict of aiming locations (actions in the policy) for each state (s,i,u) in this turn\n",
    "        prob_normalscore, prob_doublescore, prob_bullscore: the skill model \n",
    "    \n",
    "    Returns: A dict\n",
    "        result_dict['finish']: probability of finishing the game (reach zero by making a double)\n",
    "        result_dict['bust']: probability of busting the game (transit to next turn of (s=score_state,i=3,u=0))\n",
    "        result_dict['score']: probability of achieving a cumulative score_gained in this turn (transit to next turn of (s=score_state-score_gained,i=3,u=0))\n",
    "    \"\"\"    \n",
    "    \n",
    "    ##\n",
    "    result_dict = {}\n",
    "    prob_finish = 0 ## probability of finishing the game\n",
    "    prob_bust = 0   ## probability of busting the game\n",
    "    ## initialize for (s, rt=3, score_gained=0)\n",
    "    next_throw_state_len = 1\n",
    "    prob_transit_next_throw_state = np.ones(next_throw_state_len)\n",
    "    \n",
    "    for rt in [3,2,1]:\n",
    "        prob_this_throw_state = prob_transit_next_throw_state\n",
    "        this_throw_state_len = next_throw_state_len\n",
    "        next_throw_state_len = min(score_state-2, fb.maxhitscore*(4-rt)) + 1\n",
    "        prob_transit_next_throw_state = np.zeros(next_throw_state_len)  ## probability vector of total score_gained after this throw\n",
    "        \n",
    "        for score_gained in range(this_throw_state_len):\n",
    "            ## skip infeasible state\n",
    "            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                continue   \n",
    "\n",
    "            ## aimming location of the policy at this state\n",
    "            aiming_location_index = state_action[rt][0][score_gained]\n",
    "            prob_this_state = prob_this_throw_state[score_gained]\n",
    "            \n",
    "            #largest possible normal socre to make in the next throw without busting\n",
    "            score_remain = score_state - score_gained\n",
    "            score_max = min(score_remain-2, 60)\n",
    "            score_max_plus1 = score_max + 1\n",
    "        \n",
    "            ## transit to next throw or turn with normal scores\n",
    "            prob_transit_next_throw_state[score_gained:score_gained+score_max_plus1] += prob_normalscore[aiming_location_index, 0:score_max_plus1]*prob_this_state\n",
    "            ## game can not bust or end when score_max = 60, i.e.,  prob_notbust = 1\n",
    "            if (score_max < 60):\n",
    "                prob_notbust_this_state = prob_normalscore[aiming_location_index, 0:score_max+1].sum()\n",
    "                ## transit to the end of game\n",
    "                if (score_remain == fb.score_DB):\n",
    "                    prob_finish += prob_bullscore[aiming_location_index, 1]*prob_this_state\n",
    "                    prob_notbust_this_state += prob_bullscore[aiming_location_index, 1]\n",
    "                elif (score_remain <= 40 and score_remain%2==0):\n",
    "                    doublescore_index = (score_remain//2) - 1\n",
    "                    prob_finish += prob_doublescore[aiming_location_index, doublescore_index]*prob_this_state\n",
    "                    prob_notbust_this_state += prob_doublescore[aiming_location_index, doublescore_index]\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                ## transit to bust\n",
    "                prob_bust += (max(1 - prob_notbust_this_state,0))*prob_this_state\n",
    "            \n",
    "    result_dict['finish'] = prob_finish\n",
    "    result_dict['bust'] = prob_bust\n",
    "    result_dict['score'] = prob_transit_next_throw_state\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_turn_transit_probability_t(score_state, state_action, tokens, prob_normalscore_nt, prob_normalscore_t, prob_doublescore_nt,prob_doublescore_t, prob_bullscore_nt, prob_bullscore_t):\n",
    "     \n",
    "    \"\"\"\n",
    "    Solve the state transition probability after a turn playing with a specified aiming policy\n",
    "    \n",
    "    Args: \n",
    "        score_state: score at the beginning of the turn, e.g., 2,3,...,501 \n",
    "        state_action: a dict of aiming locations (actions in the policy) for each state (s,i,u) in this turn\n",
    "        prob_normalscore, prob_doublescore, prob_bullscore: the skill model \n",
    "    \n",
    "    Returns: A dict\n",
    "        result_dict['finish']: probability of finishing the game (reach zero by making a double)\n",
    "        result_dict['bust']: probability of busting the game (transit to next turn of (s=score_state,i=3,u=0))\n",
    "        result_dict['score']: probability of achieving a cumulative score_gained in this turn (transit to next turn of (s=score_state-score_gained,i=3,u=0))\n",
    "    \"\"\"    \n",
    "    \n",
    "    ##\n",
    "    result_dict = {}\n",
    "    prob_finish = 0 ## probability of finishing the game\n",
    "    prob_bust = 0   ## probability of busting the game\n",
    "    ## initialize for (s, rt=3, score_gained=0)\n",
    "    next_throw_state_len = 1\n",
    "    prob_transit_next_throw_state = np.ones(next_throw_state_len)\n",
    "    \n",
    "    for rt in [3,2,1]:\n",
    "\n",
    "        prob_this_throw_state = prob_transit_next_throw_state\n",
    "        this_throw_state_len = next_throw_state_len\n",
    "        next_throw_state_len = min(score_state-2, fb.maxhitscore*(4-rt)) + 1\n",
    "        prob_transit_next_throw_state = np.zeros(tokens,next_throw_state_len)  ## probability vector of total score_gained after this throw\n",
    "\n",
    "        for t in range(tokens+1): \n",
    "\n",
    "            for score_gained in range(this_throw_state_len):\n",
    "                ## skip infeasible state\n",
    "                if not fb.state_feasible_array[rt, score_gained]:\n",
    "                    continue   \n",
    "\n",
    "                ## aimming location of the policy at this state\n",
    "                aiming_location_index = state_action[rt][t][score_gained]\n",
    "                \n",
    "                if aiming_location_index < throw_num:\n",
    "                    policy_is_throw = True \n",
    "                    prob_normalscore = prob_normalscore_nt\n",
    "                    prob_bullscore = prob_bullscore_nt\n",
    "                    prob_doublescore = prob_doublescore_nt\n",
    "                else:\n",
    "                    policy_is_throw = False\n",
    "                    prob_normalscore = prob_normalscore_t\n",
    "                    prob_bullscore = prob_bullscore_t\n",
    "                    prob_doublescore = prob_doublescore_t\n",
    "\n",
    "                prob_this_state = prob_this_throw_state[score_gained]\n",
    "                \n",
    "                #largest possible normal socre to make in the next throw without busting\n",
    "                score_remain = score_state - score_gained\n",
    "                score_max = min(score_remain-2, 60)\n",
    "                score_max_plus1 = score_max + 1\n",
    "\n",
    "                if policy_is_throw == True: \n",
    "                    prob_transit_next_throw_state[t][score_gained:score_gained+score_max_plus1] += prob_normalscore[aiming_location_index, 0:score_max_plus1]*prob_this_state\n",
    "                else:\n",
    "                    prob_transit_next_throw_state[t-1][score_gained:score_gained+score_max_plus1] += prob_normalscore[aiming_location_index, 0:score_max_plus1]*prob_this_state\n",
    "\n",
    "                ## game can not bust or end when score_max = 60, i.e.,  prob_notbust = 1\n",
    "                if (score_max < 60):\n",
    "                    prob_notbust_this_state = prob_normalscore[aiming_location_index, 0:score_max+1].sum()\n",
    "                    ## transit to the end of game\n",
    "                    if (score_remain == fb.score_DB):\n",
    "                        prob_finish += prob_bullscore[aiming_location_index, 1]*prob_this_state\n",
    "                        prob_notbust_this_state += prob_bullscore[aiming_location_index, 1]\n",
    "                    elif (score_remain <= 40 and score_remain%2==0):\n",
    "                        doublescore_index = (score_remain//2) - 1\n",
    "                        prob_finish += prob_doublescore[aiming_location_index, doublescore_index]*prob_this_state\n",
    "                        prob_notbust_this_state += prob_doublescore[aiming_location_index, doublescore_index]\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                    ## transit to bust\n",
    "                    prob_bust += (max(1 - prob_notbust_this_state,0))*prob_this_state\n",
    "                \n",
    "    result_dict['finish'] = prob_finish\n",
    "    result_dict['bust'] = prob_bust\n",
    "    result_dict['score'] = prob_transit_next_throw_state\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_turn_transit_probability_fast_nt(score_state, state_action, prob_normalscore_nt, prob_normalscore_t, prob_doublescore_nt,prob_doublescore_t, prob_bullscore_nt, prob_bullscore_t, prob_bust_dic_nt, prob_bust_dic_t):\n",
    "    \"\"\"\n",
    "    A fast way of implementing solve_turn_transit_probability by using pre-stored prob_bust_dic\n",
    "    \"\"\"     \n",
    "    \n",
    "    result_dict = {}\n",
    "    prob_finish = 0 ## probability of finishing the game\n",
    "    prob_bust_total = 0   ## probability of busting the game\n",
    "    ## initialize for (s, rt=3, score_gained=0)\n",
    "    next_throw_state_len = 1\n",
    "    prob_transit_next_throw_state = np.ones(next_throw_state_len)\n",
    "    \n",
    "    for rt in [3,2,1]:\n",
    "        prob_this_throw_state = prob_transit_next_throw_state\n",
    "        this_throw_state_len = next_throw_state_len\n",
    "        next_throw_state_len = min(score_state-2, fb.maxhitscore*(4-rt)) + 1\n",
    "        prob_transit_next_throw_state = np.zeros(next_throw_state_len)  ## probability vector of total score_gained after this throw\n",
    "        \n",
    "        prob_normalscore_transit = prob_normalscore_nt[state_action[rt][0][0:this_throw_state_len]]*prob_this_throw_state.reshape((this_throw_state_len,1))\n",
    "        \n",
    "        for score_gained in range(this_throw_state_len):  # loop through score already gained\n",
    "            if score_state==63 and score_gained==60:\n",
    "                print('lol')\n",
    "            ## skip infeasible state\n",
    "            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                continue   \n",
    "\n",
    "            ## aimming location of the policy at this state\n",
    "            aiming_location_index = state_action[rt][0][score_gained]\n",
    "            prob_this_state = prob_this_throw_state[score_gained]\n",
    "            \n",
    "            #largest possible normal socre to make in the next throw without busting\n",
    "            score_remain = score_state - score_gained\n",
    "            score_max = min(score_remain-2, 60)\n",
    "            score_max_plus1 = score_max + 1\n",
    "        \n",
    "            ## transit to next throw or turn with normal scores            \n",
    "            prob_transit_next_throw_state[score_gained:score_gained+score_max_plus1] += prob_normalscore_transit[score_gained, 0:score_max_plus1]\n",
    "            ## game can not bust or end when score_max = 60, i.e.,  prob_notbust = 1\n",
    "            if (score_max < 60):\n",
    "                ## transit to the end of game\n",
    "                if (score_remain == fb.score_DB):\n",
    "                    prob_finish += prob_bullscore_nt[aiming_location_index, 1]*prob_this_state\n",
    "                elif (score_remain <= 40 and score_remain%2==0):\n",
    "                    doublescore_index = (score_remain//2) - 1\n",
    "                    prob_finish += prob_doublescore_nt[aiming_location_index, doublescore_index]*prob_this_state\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                #transit to bust\n",
    "                prob_bust_total += prob_bust_dic_nt[score_max][aiming_location_index]*prob_this_state\n",
    "            \n",
    "    result_dict['finish'] = prob_finish\n",
    "    result_dict['bust'] = prob_bust_total\n",
    "    result_dict['score'] = prob_transit_next_throw_state\n",
    "\n",
    "    return result_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_policy_transit_probability_nt(policy_action_index_dic, prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore):\n",
    "    \"\"\"\n",
    "    For each turn, solve the state transition probability for a specified aiming policy\n",
    "    \n",
    "    Args: \n",
    "        policy_action_index_dic: a dict of aiming locations (actions in the policy) for each state (s,i,u) of each turn s=2,...,501\n",
    "        prob_normalscore, prob_doublescore, prob_bullscore: the skill model \n",
    "    \n",
    "    Returns: A dict\n",
    "    \"\"\"  \n",
    "    \n",
    "    prob_policy_transit_dict = {}\n",
    "    t1 = time.time()\n",
    "    for score_state in range(2,502):\n",
    "        prob_policy_transit_dict[score_state] = solve_turn_transit_probability_nt(score_state, policy_action_index_dic[score_state], prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore)\n",
    "\n",
    "    t2 = time.time()\n",
    "    print('solve prob_policy_transit in {} seconds'.format(t2-t1))\n",
    "    \n",
    "    return prob_policy_transit_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_policy_transit_probability_t(policy_action_index_dic, tokens, prob_grid_normalscore_nt, prob_grid_normalscore_t, prob_grid_doublescore_nt, prob_grid_doublescore_t, prob_grid_bullscore_nt, prob_grid_bullscore_t):\n",
    "    \"\"\"\n",
    "    For each turn, solve the state transition probability for a specified aiming policy\n",
    "    \n",
    "    Args: \n",
    "        policy_action_index_dic: a dict of aiming locations (actions in the policy) for each state (s,i,u) of each turn s=2,...,501\n",
    "        prob_normalscore, prob_doublescore, prob_bullscore: the skill model \n",
    "    \n",
    "    Returns: A dict\n",
    "    \"\"\"  \n",
    "    \n",
    "    prob_policy_transit_dict = {}\n",
    "    t1 = time.time()\n",
    "    for score_state in range(2,502):\n",
    "        prob_policy_transit_dict[score_state] = solve_turn_transit_probability_t(score_state, policy_action_index_dic[score_state], tokens, prob_grid_normalscore_nt, prob_grid_normalscore_t , prob_grid_doublescore_nt , prob_grid_doublescore_t , prob_grid_bullscore_nt, prob_grid_bullscore_t)\n",
    "\n",
    "    t2 = time.time()\n",
    "    print('solve prob_policy_transit in {} seconds'.format(t2-t1))\n",
    "    \n",
    "    return prob_policy_transit_dict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Base Case - No Tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = 9\n",
    "max_token_index = tokens + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_69156/2526509755.py:273: RuntimeWarning: divide by zero encountered in divide\n",
      "  num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic_nt[score_max]\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_69156/2526509755.py:273: RuntimeWarning: overflow encountered in divide\n",
      "  num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic_nt[score_max]\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_69156/2526509755.py:286: RuntimeWarning: divide by zero encountered in divide\n",
      "  value_relerror[rt][0] = np.abs((state_value_update[rt][0] - state_value[rt][0])/state_value_update[rt][0]).max()\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_69156/2526509755.py:286: RuntimeWarning: invalid value encountered in divide\n",
      "  value_relerror[rt][0] = np.abs((state_value_update[rt][0] - state_value[rt][0])/state_value_update[rt][0]).max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n",
      "lol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_69156/2526509755.py:286: RuntimeWarning: invalid value encountered in divide\n",
      "  value_relerror[rt][0] = np.abs((state_value_update[rt][0] - state_value[rt][0])/state_value_update[rt][0]).max()\n",
      "/Users/rachael/Desktop/darts-thesis/function_solve_dp_tokens.py:174: RuntimeWarning: divide by zero encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n",
      "/Users/rachael/Desktop/darts-thesis/function_solve_dp_tokens.py:174: RuntimeWarning: overflow encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n",
      "/Users/rachael/Desktop/darts-thesis/function_solve_dp_tokens.py:212: RuntimeWarning: divide by zero encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n",
      "/Users/rachael/Desktop/darts-thesis/function_solve_dp_tokens.py:212: RuntimeWarning: overflow encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solve prob_policy_transit in 0.3336198329925537 seconds\n",
      "solve dp_turn_policyiter in 325.19933891296387 seconds\n",
      "[[0.     0.     1.4381 ... 5.0818 5.0845 5.0965]\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]\n",
      " ...\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "turn_transit_list = {}\n",
    "\n",
    "####### ------ No Tokens ------ #######\n",
    "## aiming_grid\n",
    "num_aiming_location = aiming_grid.shape[0]\n",
    "prob_normalscore_nt = prob_grid_normalscore_nt\n",
    "prob_doublescore_dic_nt = {}\n",
    "for doublescore_index in range(20):\n",
    "    doublescore = 2*(doublescore_index+1)\n",
    "    prob_doublescore_dic_nt[doublescore] = np.array(prob_grid_doublescore_nt[:,doublescore_index])\n",
    "prob_DB_nt = np.array(prob_grid_bullscore_nt[:,1])\n",
    "\n",
    "## the probability of not bust for each action given score_max=i (score_remain=i+2)\n",
    "prob_bust_dic_nt = {}\n",
    "prob_notbust_dic_nt = {}\n",
    "for score_max in range(60):    \n",
    "    ## transit to next throw or turn\n",
    "    prob_notbust_nt = prob_grid_normalscore_nt[:,0:score_max+1].sum(axis=1)\n",
    "    ## transit to the end of game\n",
    "    score_remain = score_max + 2\n",
    "    if (score_remain == fb.score_DB):\n",
    "        prob_notbust_nt += prob_DB_nt\n",
    "    elif (score_remain <= 40 and score_remain%2==0):\n",
    "        prob_notbust_nt += prob_doublescore_dic_nt[score_remain]\n",
    "    ##\n",
    "    prob_notbust_nt = np.minimum(np.maximum(prob_notbust_nt, 0),1)\n",
    "    prob_notbust_dic_nt[score_max] = prob_notbust_nt\n",
    "    prob_bust_dic_nt[score_max] = 1 - prob_notbust_dic_nt[score_max]\n",
    "\n",
    "prob_normalscore_tensor_nt = torch.from_numpy(prob_normalscore_nt)\n",
    "\n",
    "####### ------ Tokens ------ #######\n",
    "## aiming_grid\n",
    "prob_normalscore_t = prob_grid_normalscore_t\n",
    "prob_doublescore_dic_t = {}\n",
    "for doublescore_index in range(20):\n",
    "    doublescore = 2*(doublescore_index+1)\n",
    "    prob_doublescore_dic_t[doublescore] = np.array(prob_grid_doublescore_t[:,doublescore_index])\n",
    "prob_DB_t = np.array(prob_grid_bullscore_t[:,1])\n",
    "\n",
    "## the probability of not bust for each action given score_max=i (score_remain=i+2)\n",
    "prob_bust_dic_t = {}\n",
    "prob_notbust_dic_t = {}\n",
    "for score_max in range(60):    \n",
    "    ## transit to next throw or turn\n",
    "    prob_notbust_t = prob_grid_normalscore_t[:,0:score_max+1].sum(axis=1)\n",
    "    ## transit to the end of game\n",
    "    score_remain = score_max + 2\n",
    "    if (score_remain == fb.score_DB):\n",
    "        prob_notbust_t += prob_DB_t\n",
    "    elif (score_remain <= 40 and score_remain%2==0):\n",
    "        prob_notbust_t += prob_doublescore_dic_t[score_remain]\n",
    "    ##\n",
    "    prob_notbust_t = np.minimum(np.maximum(prob_notbust_t, 0),1)\n",
    "    prob_notbust_dic_t[score_max] = prob_notbust_t\n",
    "    prob_bust_dic_t[score_max] = 1 - prob_notbust_dic_t[score_max]\n",
    "\n",
    "prob_normalscore_tensor_t = torch.from_numpy(prob_normalscore_t)\n",
    "\n",
    "iteration_round_limit = 20\n",
    "iteration_relerror_limit = 10**-9\n",
    "\n",
    "#### state space example of (SB=25 DB=50) ####\n",
    "## rt: the number of remaining throws in a turn\n",
    "## state_infeasible_rt2 = [23, 29, 31, 35, 37, 41, 43, 44, 46, 47, 49, 52, 53, 55, 56, 58, 59]\n",
    "## state_infeasible_rt1 = [103, 106, 109, 112, 113, 115, 116, 118, 119]    \n",
    "\n",
    "optimal_value_rt3 = np.zeros((max_token_index,502))\n",
    "optimal_value_dic = {}\n",
    "optimal_action_index_dic= {}\n",
    "\n",
    "num_iteration_record = np.zeros((max_token_index,502), dtype=np.int32)\n",
    "\n",
    "state_len_vector = np.zeros(4, dtype=np.int32)\n",
    "state_value  = [None]  ## optimal value (expected # of turns to finish the game) for each state in the current playing turn\n",
    "state_action = [None]  ## aimming locations for for each state in the current playing turn\n",
    "action_diff  = [None]\n",
    "value_relerror = np.zeros((max_token_index,4))\n",
    "\n",
    "for rt in [1,2,3]:\n",
    "\n",
    "    ## for rt=3: possible score_gained = 0\n",
    "    ## for rt=2: possible score_gained = 0,1,...,60\n",
    "    ## for rt=1: possible score_gained = 0,1,...,120\n",
    "\n",
    "    # Number of possible scores for given remaining throws (rt) in the turn\n",
    "    this_throw_state_len = fb.maxhitscore*(3-rt) + 1\n",
    "\n",
    "    # Create stacked state value, action and action diff objects \n",
    "    # Rows will be token values, columns will be remaining scores \n",
    "    state_value.append(np.ones((max_token_index,this_throw_state_len))*fb.largenumber)\n",
    "    state_action.append(np.ones((max_token_index,this_throw_state_len), np.int32)*fb.infeasible_marker)\n",
    "    action_diff.append(np.ones((max_token_index,this_throw_state_len)))\n",
    "\n",
    "# Add these to the state value update objects \n",
    "state_value_update = ft.copy_numberarray_container(state_value)\n",
    "state_action_update = ft.copy_numberarray_container(state_action)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for t in range(0,max_token_index):\n",
    "\n",
    "    ## use no_turn policy as the initial policy \n",
    "    [noturn_optimal_value, noturn_optimal_action_index] = fsdt.solve_dp_noturn_tokens(aiming_grid, prob_grid_normalscore_nt, prob_grid_normalscore_t, tokens = t, prob_grid_doublescore=prob_grid_doublescore_nt, prob_grid_bullscore=prob_grid_bullscore_nt,prob_grid_doublescore_t=prob_grid_doublescore_t, prob_grid_bullscore_t=prob_grid_bullscore_t)\n",
    "\n",
    "    if t==0:\n",
    "\n",
    "        for score_state in range(2, 502):\n",
    "            \n",
    "            # if score_state == 70:\n",
    "            #     print('lol')\n",
    "\n",
    "            turn_transit_list[score_state] = []\n",
    "\n",
    "            # if score_state == 3:\n",
    "            #     break \n",
    "            #print('#### solve_dp_turn score_state={} ####'.format(score_state))    \n",
    "            \n",
    "            ## initialization \n",
    "            for rt in [1,2,3]:\n",
    "                ## for rt=3: score_gained = 0\n",
    "                ## for rt=2: score_gained = 0,1,...,min(s-2,60)\n",
    "                ## for rt=1: score_gained = 0,1,...,min(s-2,120)\n",
    "                this_throw_state_len = min(score_state-2, fb.maxhitscore*(3-rt)) + 1\n",
    "                state_len_vector[rt] = this_throw_state_len\n",
    "                        \n",
    "                ## initialize the starting policy: \n",
    "                ## use no_turn action in (s, i, u=0)\n",
    "                ## use turn action (s-1, i, u-1) in (s, i, u!=0) if (s-1, i, u-1) is feasible state\n",
    "                state_action[rt][0] = noturn_optimal_action_index[0,score_state]            \n",
    "                for score_gained in range(1,this_throw_state_len):                \n",
    "                    if fb.state_feasible_array[rt, score_gained]:  ## if True\n",
    "                        if fb.state_feasible_array[rt, score_gained-1]:\n",
    "                            state_action[rt][0][score_gained] = optimal_action_index_dic[score_state-1][rt][0][score_gained-1]\n",
    "                        else:                        \n",
    "                            state_action[rt][0][score_gained] = noturn_optimal_action_index[0,score_state-score_gained]\n",
    "                    else:\n",
    "                        state_action[rt][0][score_gained] = fb.infeasible_marker\n",
    "\n",
    "            ## policy iteration\n",
    "            for round_index in range(iteration_round_limit):\n",
    "\n",
    "                ## policy evaluation\n",
    "                rt = 3\n",
    "                score_gained = 0\n",
    "                score_max_turn = min(score_state-2, 3*fb.maxhitscore)\n",
    "                if score_state==63:\n",
    "                    print('lol')\n",
    "                prob_turn_transit_nt = solve_turn_transit_probability_fast_nt(score_state, state_action, prob_grid_normalscore_nt, prob_grid_normalscore_t, prob_grid_doublescore_nt, prob_grid_doublescore_t, prob_grid_bullscore_nt, prob_grid_bullscore_t, prob_bust_dic_nt, prob_bust_dic_t)        \n",
    "                turn_transit_list[score_state].append(prob_turn_transit_nt.copy())\n",
    "                prob_turn_zeroscore = prob_turn_transit_nt['bust'] + prob_turn_transit_nt['score'][0]\n",
    "                new_value_rt3 = (1 + np.dot(prob_turn_transit_nt['score'][1:], optimal_value_rt3[0,score_state-1:score_state-score_max_turn-1:-1])) / (1-prob_turn_zeroscore)\n",
    "                state_value_update[rt][0][score_gained] = new_value_rt3\n",
    "                optimal_value_rt3[0,score_state] = new_value_rt3\n",
    "                #print('evaluate rt3 value= {}'.format(new_value_rt3)\n",
    "\n",
    "                ## policy improvement\n",
    "                for rt in [1,2,3]:            \n",
    "                    this_throw_state_len = state_len_vector[rt]\n",
    "                    \n",
    "                    ## state which can not bust.  score_state-score_gained>=62 \n",
    "                    state_notbust_len =  max(min(score_state-61, this_throw_state_len),0)\n",
    "                    if (state_notbust_len > 0):\n",
    "                        if (rt==1 and round_index==0):\n",
    "                            ## combine all non-bust states together \n",
    "                            state_notbust_update_index = state_notbust_len                    \n",
    "                            next_state_value_array = np.zeros((61, state_notbust_len))                    \n",
    "                            for score_gained in range(state_notbust_len):\n",
    "                                ## skip infeasible state\n",
    "                                if not fb.state_feasible_array[rt, score_gained]:\n",
    "                                    continue\n",
    "                                score_remain = score_state - score_gained\n",
    "                                score_max = 60 ## always 60 here\n",
    "                                score_max_plus1 = score_max + 1\n",
    "                                next_state_value_array[:,score_gained] = optimal_value_rt3[0,score_remain:score_remain-score_max_plus1:-1]\n",
    "                        elif (rt==2 and (round_index==0 or score_state<182)):\n",
    "                            ## combine all non-bust states together \n",
    "                            state_notbust_update_index = state_notbust_len\n",
    "                            next_state_value_array = np.zeros((61, state_notbust_len))                    \n",
    "                            for score_gained in range(state_notbust_len):\n",
    "                                ## skip infeasible state\n",
    "                                if not fb.state_feasible_array[rt, score_gained]:\n",
    "                                    continue\n",
    "                                score_remain = score_state - score_gained\n",
    "                                score_max = 60 ## always 60 here\n",
    "                                score_max_plus1 = score_max + 1\n",
    "                                next_state_value_array[:,score_gained] = state_value_update[rt-1][0][score_gained:score_gained+score_max_plus1]\n",
    "                        else: ##(rt==1 and round_index>0) or (rt==2 and round_index>0 and score_state>=182) or (rt==3)\n",
    "                            ## only update state of score_gained = 0\n",
    "                            state_notbust_update_index = 1\n",
    "                            next_state_value_array = np.zeros(61)\n",
    "                            score_gained = 0\n",
    "                            score_remain = score_state - score_gained\n",
    "                            score_max = 60 ## always 60 here\n",
    "                            score_max_plus1 = score_max + 1                    \n",
    "                            ## make a copy\n",
    "                            if (rt > 1):\n",
    "                                next_state_value_array[:] = state_value_update[rt-1][0][score_gained:score_gained+score_max_plus1]\n",
    "                            ## transit to next turn when rt=1\n",
    "                            else:\n",
    "                                next_state_value_array[:] = optimal_value_rt3[0,score_remain:score_remain-score_max_plus1:-1]\n",
    "\n",
    "                        ## matrix product to compute all together\n",
    "                        next_state_value_tensor = torch.from_numpy(next_state_value_array)\n",
    "                        ## transit to next throw in the same turn when rt=3,2\n",
    "                        ## -----------TOKEN LOGIC -------------\n",
    "                        if (rt > 1):                    \n",
    "                            num_turns_tensor = prob_normalscore_tensor_nt.matmul(next_state_value_tensor)\n",
    "                        ## transit to next turn when rt=1\n",
    "                        else:\n",
    "                            num_turns_tensor = 1 + prob_normalscore_tensor_nt.matmul(next_state_value_tensor)\n",
    "\n",
    "                        ## searching\n",
    "                        temp1 = num_turns_tensor.min(axis=0)                \n",
    "                        state_action_update[rt][0][0:state_notbust_update_index] = temp1.indices.numpy()\n",
    "                        state_value_update[rt][0][0:state_notbust_update_index] =  temp1.values.numpy()                \n",
    "                    \n",
    "                    ## state which possibly bust.  score_state-score_gained<62 \n",
    "                    if (state_notbust_len < this_throw_state_len):\n",
    "                        ## combine all bust states together \n",
    "                        state_bust_len = this_throw_state_len - state_notbust_len\n",
    "                        next_state_value_array = np.zeros((61, state_bust_len))\n",
    "                        for score_gained in range(state_notbust_len, this_throw_state_len):\n",
    "                            ## skip infeasible state\n",
    "                            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                                continue\n",
    "                            score_remain = score_state - score_gained\n",
    "                            #score_max = min(score_remain-2, 60)\n",
    "                            score_max = score_remain-2 ## less than 60 here\n",
    "                            score_max_plus1 = score_max + 1\n",
    "                            score_gained_index = score_gained - state_notbust_len ## index off set\n",
    "                            if (rt > 1):\n",
    "                                next_state_value_array[0:score_max_plus1,score_gained_index] = state_value_update[rt-1][0][score_gained:score_gained+score_max_plus1]\n",
    "                            ## transit to next turn when rt=1\n",
    "                            else:\n",
    "                                next_state_value_array[0:score_max_plus1,score_gained_index] = optimal_value_rt3[0,score_remain:score_remain-score_max_plus1:-1]\n",
    "                        \n",
    "                        next_state_value_tensor = torch.from_numpy(next_state_value_array)\n",
    "                        ## transit to next throw in the same turn when rt=3,2\n",
    "                        if (rt > 1):                    \n",
    "                            num_turns_tensor = prob_normalscore_tensor_nt.matmul(next_state_value_tensor)\n",
    "                        ## transit to next turn when rt=1\n",
    "                        else:\n",
    "                            num_turns_tensor = 1 + prob_normalscore_tensor_nt.matmul(next_state_value_tensor)                                                               \n",
    "\n",
    "                        ## consider bust/finishing for each bust state seperately \n",
    "                        num_turns_array = num_turns_tensor.numpy()                \n",
    "                        for score_gained in range(state_notbust_len, this_throw_state_len):\n",
    "                            ## skip infeasible state\n",
    "                            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                                continue\n",
    "                            score_remain = score_state - score_gained\n",
    "                            #score_max = min(score_remain-2, 60)\n",
    "                            score_max = score_remain-2 ## less than 60 here\n",
    "                            score_max_plus1 = score_max + 1\n",
    "                            score_gained_index = score_gained - state_notbust_len\n",
    "                            \n",
    "                            #nums_turn_array =  value to go from this state, given this action and this score gained\n",
    "                            \n",
    "                            ## transit to the end of game\n",
    "                            if (rt > 1):\n",
    "                                if (score_remain == fb.score_DB):                        \n",
    "                                    num_turns_array[:,score_gained_index] += prob_DB_nt\n",
    "                                elif (score_remain <= 40 and score_remain%2==0):\n",
    "                                    num_turns_array[:,score_gained_index] += prob_doublescore_dic_nt[score_remain]\n",
    "                                else:\n",
    "                                    pass\n",
    "\n",
    "                            ## transit to bust\n",
    "                            if (rt==3):\n",
    "                                num_turns_array[:,score_gained_index] += prob_bust_dic_nt[score_max]\n",
    "                                ## solve an equation other than using the policy evaluation value (s,i=3,u=0)\n",
    "                                num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic_nt[score_max] \n",
    "                            elif (rt==2):\n",
    "                                num_turns_array[:,score_gained_index] += prob_bust_dic_nt[score_max]*(1+new_value_rt3)\n",
    "                            else:\n",
    "                                num_turns_array[:,score_gained_index] += prob_bust_dic_nt[score_max]*(new_value_rt3)  ## 1 turn is already counted before\n",
    "\n",
    "                        ## searching\n",
    "                        temp1 = num_turns_tensor.min(axis=0)\n",
    "                        state_action_update[rt][0][state_notbust_len:this_throw_state_len] = temp1.indices.numpy()\n",
    "                        state_value_update[rt][0][state_notbust_len:this_throw_state_len] =  temp1.values.numpy()                \n",
    "\n",
    "                    #### finish rt=1,2,3. check improvement\n",
    "                    action_diff[rt][0][:] = np.abs(state_action_update[rt][0] - state_action[rt][0])                                \n",
    "                    value_relerror[rt][0] = np.abs((state_value_update[rt][0] - state_value[rt][0])/state_value_update[rt][0]).max()\n",
    "                    state_action[rt][0][:] = state_action_update[rt][0][:]\n",
    "                    state_value[rt][0][:] = state_value_update[rt][0][:]\n",
    "\n",
    "                max_action_diff = max([action_diff[1].max(), action_diff[2].max(), action_diff[3].max()])\n",
    "                max_value_relerror = value_relerror.max()            \n",
    "                \n",
    "                if (max_action_diff < 1):\n",
    "                #if max_value_relerror < iteration_relerror_limit:\n",
    "                    num_iteration_record[score_state] = round_index + 1\n",
    "                    break\n",
    "\n",
    "            for rt in [1,2,3]:\n",
    "                state_value_update[rt][0][fb.state_infeasible[rt]] = fb.largenumber\n",
    "                state_action_update[rt][0][fb.state_infeasible[rt]] = fb.infeasible_marker\n",
    "            optimal_action_index_dic[score_state] = ft.copy_numberarray_container(state_action_update)\n",
    "            optimal_value_dic[score_state] = ft.copy_numberarray_container(state_value_update, new_dtype=fb.result_float_dytpe)\n",
    "            optimal_value_rt3[0,score_state] = state_value[3][0]\n",
    "            ## done:V(s,i=3/2/1,u)\n",
    "\n",
    "##\n",
    "prob_scorestate_transit = {}    \n",
    "prob_scorestate_transit =  solve_policy_transit_probability_nt(optimal_action_index_dic, prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore)\n",
    "t2 = time.time()\n",
    "print('solve dp_turn_policyiter in {} seconds'.format(t2-t1))\n",
    "\n",
    "print(optimal_value_rt3)\n",
    "result_dic = {'optimal_value_dic':optimal_value_dic, 'optimal_action_index_dic':optimal_action_index_dic, 'optimal_value_rt3':optimal_value_rt3, 'prob_scorestate_transit':prob_scorestate_transit}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_turn_transit_nt['score'].shape\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Scalable Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_turn_transit_probability_fast_t(score_state, state_action, tokens, prob_normalscore_nt, prob_normalscore_t, prob_doublescore_nt,prob_doublescore_t, prob_bullscore_nt, prob_bullscore_t, prob_bust_dic_nt, prob_bust_dic_t):\n",
    "    \"\"\"\n",
    "    A fast way of implementing solve_turn_transit_probability by using pre-stored prob_bust_dic\n",
    "    \"\"\"     \n",
    "    \n",
    "    result_dict = {}\n",
    "    prob_finish = 0 ## probability of finishing the game\n",
    "    prob_bust_total = 0   ## probability of busting the game\n",
    "    ## initialize for (s, rt=3, score_gained=0)\n",
    "    next_throw_state_len = 1\n",
    "    tokens_turn = min(3,max(0,tokens-3))\n",
    "    prob_transit_next_throw_state = np.ones((tokens_turn+1,next_throw_state_len))\n",
    "\n",
    "\n",
    "    for rt in [3,2,1]:\n",
    "\n",
    "        prob_this_throw_state = prob_transit_next_throw_state[0]\n",
    "        this_throw_state_len = next_throw_state_len\n",
    "        next_throw_state_len = min(score_state-2, fb.maxhitscore*(4-rt)) + 1\n",
    "        prob_transit_next_throw_state = np.zeros((tokens_turn+1, next_throw_state_len))  ## probability vector of total score_gained after this throw\n",
    "            \n",
    "        policy = state_action[rt][max(0,tokens-3):tokens+1 , 0:this_throw_state_len]\n",
    "\n",
    "        prob_normalscore_transit = np.zeros((tokens_turn+1,this_throw_state_len,1))\n",
    "                \n",
    "        for tt in range(tokens_turn+1):\n",
    "\n",
    "            # True if policy says throw, false otherwise \n",
    "            policy_nt = policy[tt] < throw_num\n",
    "            # True if policy says use token, false otherwise \n",
    "            policy_t = policy[tt] >= throw_num\n",
    "\n",
    "            # Create transit probabilities\n",
    "            if tt == 0:\n",
    "                prob_normalscore_transit[tt] = (prob_normalscore_nt[state_action[rt][tokens]][0:this_throw_state_len] * policy_nt * prob_this_throw_state[tt]).reshape((this_throw_state_len,1))\n",
    "            else: \n",
    "                # You still have a token if you choose to throw\n",
    "                prob_normalscore_transit[tt] = (prob_normalscore_nt[state_action[rt][tokens]][0:this_throw_state_len] * policy_nt * prob_this_throw_state[tt]).reshape((this_throw_state_len,1))\n",
    "                # You lose a token if you choose to use it\n",
    "                prob_normalscore_transit[tt-1] += (prob_normalscore_t[state_action[rt][tokens]][0:this_throw_state_len] * policy_t * prob_this_throw_state[tt]).reshape((this_throw_state_len,1))\n",
    "\n",
    "            # prob_normalscore_transit = prob_normalscore_nt[state_action[rt][tokens][0:this_throw_state_len]]*prob_this_throw_state.reshape((this_throw_state_len,1))\n",
    "        \n",
    "        for score_gained in range(this_throw_state_len):  # loop through score already gained\n",
    "\n",
    "            # if score_state==63 and score_gained==60:\n",
    "            #     print('lol')\n",
    "\n",
    "            for tt in range(tokens_turn+1):\n",
    "\n",
    "                ## skip infeasible state\n",
    "                if not fb.state_feasible_array[rt, score_gained]:\n",
    "                    continue   \n",
    "\n",
    "                ## aimming location of the policy at this state\n",
    "                aiming_location_index = state_action[rt][tt][score_gained]\n",
    "                \n",
    "                if aiming_location_index < throw_num:\n",
    "                    policy_is_throw = True \n",
    "                else:\n",
    "                    policy_is_throw = False \n",
    "\n",
    "                prob_this_state = prob_this_throw_state[score_gained]\n",
    "                \n",
    "                #largest possible normal socre to make in the next throw without busting\n",
    "                score_remain = score_state - score_gained\n",
    "                score_max = min(score_remain-2, 60)\n",
    "                score_max_plus1 = score_max + 1\n",
    "            \n",
    "                ## transit to next throw or turn with normal scores            \n",
    "                prob_transit_next_throw_state[tt][score_gained:score_gained+score_max_plus1] += prob_normalscore_transit[tt,score_gained, 0:score_max_plus1]\n",
    "                \n",
    "                ## game can not bust or end when score_max = 60, i.e.,  prob_notbust = 1\n",
    "                if (score_max < 60):\n",
    "                    ## transit to the end of game\n",
    "                    if (score_remain == fb.score_DB):\n",
    "                        if policy_is_throw == True :\n",
    "                            prob_finish += prob_bullscore_nt[aiming_location_index, 1]*prob_this_state\n",
    "                        else: \n",
    "                            prob_finish += prob_bullscore_t[aiming_location_index, 1]*prob_this_state\n",
    "                    elif (score_remain <= 40 and score_remain%2==0):\n",
    "                        if policy_is_throw == True :\n",
    "                            doublescore_index = (score_remain//2) - 1\n",
    "                            prob_finish += prob_doublescore_nt[aiming_location_index, doublescore_index]*prob_this_state\n",
    "                        else: \n",
    "                            doublescore_index = (score_remain//2) - 1\n",
    "                            prob_finish += prob_doublescore_t[aiming_location_index, doublescore_index]*prob_this_state\n",
    "                        \n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                    #transit to bust\n",
    "                    if policy_is_throw == True :\n",
    "                        prob_bust_total += prob_bust_dic_nt[score_max][aiming_location_index]*prob_this_state\n",
    "                    else:\n",
    "                        prob_bust_total += prob_bust_dic_t[score_max][aiming_location_index]*prob_this_state\n",
    "                \n",
    "    result_dict['finish'] = prob_finish\n",
    "    result_dict['bust'] = prob_bust_total\n",
    "    result_dict['score'] = prob_transit_next_throw_state\n",
    "\n",
    "    return result_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = 9\n",
    "max_token_index = tokens + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachael/Desktop/darts-thesis/function_solve_dp_tokens.py:174: RuntimeWarning: divide by zero encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n",
      "/Users/rachael/Desktop/darts-thesis/function_solve_dp_tokens.py:174: RuntimeWarning: overflow encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 61 into shape (1,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 144\u001b[0m\n\u001b[1;32m    141\u001b[0m score_max_turn \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(score_state\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m\u001b[39m*\u001b[39mfb\u001b[39m.\u001b[39mmaxhitscore)\n\u001b[1;32m    142\u001b[0m \u001b[39m# if score_state==63:\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m#     print('lol')\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m prob_turn_transit \u001b[39m=\u001b[39m solve_turn_transit_probability_fast_t(score_state, state_action, t, prob_normalscore_nt, prob_normalscore_t, prob_grid_doublescore_nt,prob_grid_doublescore_t, prob_grid_bullscore_nt, prob_grid_bullscore_t, prob_bust_dic_nt, prob_bust_dic_t)\n\u001b[1;32m    145\u001b[0m turn_transit_list[score_state]\u001b[39m.\u001b[39mappend(prob_turn_transit\u001b[39m.\u001b[39mcopy())\n\u001b[1;32m    146\u001b[0m prob_turn_zeroscore \u001b[39m=\u001b[39m prob_turn_transit[\u001b[39m'\u001b[39m\u001b[39mbust\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m prob_turn_transit[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[82], line 35\u001b[0m, in \u001b[0;36msolve_turn_transit_probability_fast_t\u001b[0;34m(score_state, state_action, tokens, prob_normalscore_nt, prob_normalscore_t, prob_doublescore_nt, prob_doublescore_t, prob_bullscore_nt, prob_bullscore_t, prob_bust_dic_nt, prob_bust_dic_t)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m# Create transit probabilities\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m tt \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 35\u001b[0m     prob_normalscore_transit[tt] \u001b[39m=\u001b[39m (prob_normalscore_nt[state_action[rt][tokens]][\u001b[39m0\u001b[39;49m:this_throw_state_len] \u001b[39m*\u001b[39;49m policy_nt \u001b[39m*\u001b[39;49m prob_this_throw_state[tt])\u001b[39m.\u001b[39;49mreshape((this_throw_state_len,\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     36\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[1;32m     37\u001b[0m     \u001b[39m# You still have a token if you choose to throw\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     prob_normalscore_transit[tt] \u001b[39m=\u001b[39m (prob_normalscore_nt[state_action[rt][tokens]][\u001b[39m0\u001b[39m:this_throw_state_len] \u001b[39m*\u001b[39m policy_nt \u001b[39m*\u001b[39m prob_this_throw_state[tt])\u001b[39m.\u001b[39mreshape((this_throw_state_len,\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 61 into shape (1,1)"
     ]
    }
   ],
   "source": [
    "turn_transit_list = {}\n",
    "\n",
    "####### ------ No Tokens ------ #######\n",
    "## aiming_grid\n",
    "num_aiming_location = aiming_grid.shape[0]\n",
    "prob_normalscore_nt = prob_grid_normalscore_nt\n",
    "prob_doublescore_dic_nt = {}\n",
    "for doublescore_index in range(20):\n",
    "    doublescore = 2*(doublescore_index+1)\n",
    "    prob_doublescore_dic_nt[doublescore] = np.array(prob_grid_doublescore_nt[:,doublescore_index])\n",
    "prob_DB_nt = np.array(prob_grid_bullscore_nt[:,1])\n",
    "\n",
    "## the probability of not bust for each action given score_max=i (score_remain=i+2)\n",
    "prob_bust_dic_nt = {}\n",
    "prob_notbust_dic_nt = {}\n",
    "for score_max in range(60):    \n",
    "    ## transit to next throw or turn\n",
    "    prob_notbust_nt = prob_grid_normalscore_nt[:,0:score_max+1].sum(axis=1)\n",
    "    ## transit to the end of game\n",
    "    score_remain = score_max + 2\n",
    "    if (score_remain == fb.score_DB):\n",
    "        prob_notbust_nt += prob_DB_nt\n",
    "    elif (score_remain <= 40 and score_remain%2==0):\n",
    "        prob_notbust_nt += prob_doublescore_dic_nt[score_remain]\n",
    "    ##\n",
    "    prob_notbust_nt = np.minimum(np.maximum(prob_notbust_nt, 0),1)\n",
    "    prob_notbust_dic_nt[score_max] = prob_notbust_nt\n",
    "    prob_bust_dic_nt[score_max] = 1 - prob_notbust_dic_nt[score_max]\n",
    "\n",
    "prob_normalscore_tensor_nt = torch.from_numpy(prob_normalscore_nt)\n",
    "\n",
    "####### ------ Tokens ------ #######\n",
    "## aiming_grid\n",
    "prob_normalscore_t = prob_grid_normalscore_t\n",
    "prob_doublescore_dic_t = {}\n",
    "for doublescore_index in range(20):\n",
    "    doublescore = 2*(doublescore_index+1)\n",
    "    prob_doublescore_dic_t[doublescore] = np.array(prob_grid_doublescore_t[:,doublescore_index])\n",
    "prob_DB_t = np.array(prob_grid_bullscore_t[:,1])\n",
    "\n",
    "## the probability of not bust for each action given score_max=i (score_remain=i+2)\n",
    "prob_bust_dic_t = {}\n",
    "prob_notbust_dic_t = {}\n",
    "for score_max in range(60):    \n",
    "    ## transit to next throw or turn\n",
    "    prob_notbust_t = prob_grid_normalscore_t[:,0:score_max+1].sum(axis=1)\n",
    "    ## transit to the end of game\n",
    "    score_remain = score_max + 2\n",
    "    if (score_remain == fb.score_DB):\n",
    "        prob_notbust_t += prob_DB_t\n",
    "    elif (score_remain <= 40 and score_remain%2==0):\n",
    "        prob_notbust_t += prob_doublescore_dic_t[score_remain]\n",
    "    ##\n",
    "    prob_notbust_t = np.minimum(np.maximum(prob_notbust_t, 0),1)\n",
    "    prob_notbust_dic_t[score_max] = prob_notbust_t\n",
    "    prob_bust_dic_t[score_max] = 1 - prob_notbust_dic_t[score_max]\n",
    "\n",
    "prob_normalscore_tensor_t = torch.from_numpy(prob_normalscore_t)\n",
    "\n",
    "iteration_round_limit = 20\n",
    "iteration_relerror_limit = 10**-9\n",
    "\n",
    "#### state space example of (SB=25 DB=50) ####\n",
    "## rt: the number of remaining throws in a turn\n",
    "## state_infeasible_rt2 = [23, 29, 31, 35, 37, 41, 43, 44, 46, 47, 49, 52, 53, 55, 56, 58, 59]\n",
    "## state_infeasible_rt1 = [103, 106, 109, 112, 113, 115, 116, 118, 119]    \n",
    "\n",
    "optimal_value_rt3 = np.zeros((max_token_index,502))\n",
    "optimal_value_dic = {}\n",
    "optimal_action_index_dic= {}\n",
    "\n",
    "num_iteration_record = np.zeros((max_token_index,502), dtype=np.int32)\n",
    "\n",
    "state_len_vector = np.zeros(4, dtype=np.int32)\n",
    "state_value  = [None]  ## optimal value (expected # of turns to finish the game) for each state in the current playing turn\n",
    "state_action = [None]  ## aimming locations for for each state in the current playing turn\n",
    "action_diff  = [None]\n",
    "value_relerror = np.zeros((max_token_index,4))\n",
    "\n",
    "for rt in [1,2,3]:\n",
    "\n",
    "    ## for rt=3: possible score_gained = 0\n",
    "    ## for rt=2: possible score_gained = 0,1,...,60\n",
    "    ## for rt=1: possible score_gained = 0,1,...,120\n",
    "\n",
    "    # Number of possible scores for given remaining throws (rt) in the turn\n",
    "    this_throw_state_len = fb.maxhitscore*(3-rt) + 1\n",
    "\n",
    "    # Create stacked state value, action and action diff objects \n",
    "    # Rows will be token values, columns will be remaining scores \n",
    "    state_value.append(np.ones((max_token_index,this_throw_state_len))*fb.largenumber)\n",
    "    state_action.append(np.ones((max_token_index,this_throw_state_len), np.int32)*fb.infeasible_marker)\n",
    "    action_diff.append(np.ones((max_token_index,this_throw_state_len)))\n",
    "\n",
    "# Add these to the state value update objects \n",
    "state_value_update = ft.copy_numberarray_container(state_value)\n",
    "state_action_update = ft.copy_numberarray_container(state_action)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for t in range(0,max_token_index):\n",
    "\n",
    "    ## use no_turn policy as the initial policy \n",
    "    [noturn_optimal_value, noturn_optimal_action_index] = fsdt.solve_dp_noturn_tokens(aiming_grid, prob_grid_normalscore_nt, prob_grid_normalscore_t, tokens = t, prob_grid_doublescore=prob_grid_doublescore_nt, prob_grid_bullscore=prob_grid_bullscore_nt,prob_grid_doublescore_t=prob_grid_doublescore_t, prob_grid_bullscore_t=prob_grid_bullscore_t)\n",
    "\n",
    "    for score_state in range(2, 502):\n",
    "\n",
    "        turn_transit_list[score_state] = []\n",
    "\n",
    "        # if score_state == 3:\n",
    "        #     print('lol') \n",
    "        #print('#### solve_dp_turn score_state={} ####'.format(score_state))    \n",
    "        \n",
    "        ## initialization \n",
    "        for rt in [1,2,3]:\n",
    "            ## for rt=3: score_gained = 0\n",
    "            ## for rt=2: score_gained = 0,1,...,min(s-2,60)\n",
    "            ## for rt=1: score_gained = 0,1,...,min(s-2,120)\n",
    "            this_throw_state_len = min(score_state-2, fb.maxhitscore*(3-rt)) + 1\n",
    "            state_len_vector[rt] = this_throw_state_len\n",
    "                    \n",
    "            ## initialize the starting policy: \n",
    "            ## use no_turn action in (s, i, u=0)\n",
    "            ## use turn action (s-1, i, u-1) in (s, i, u!=0) if (s-1, i, u-1) is feasible state\n",
    "            state_action[rt][t] = noturn_optimal_action_index[t,score_state]            \n",
    "            for score_gained in range(1,this_throw_state_len):                \n",
    "                if fb.state_feasible_array[rt, score_gained]:  ## if True\n",
    "                    if fb.state_feasible_array[rt, score_gained-1]:\n",
    "                        state_action[rt][t][score_gained] = optimal_action_index_dic[score_state-1][rt][t][score_gained-1]\n",
    "                    else:                        \n",
    "                        state_action[rt][t][score_gained] = noturn_optimal_action_index[t,score_state-score_gained]\n",
    "                else:\n",
    "                    state_action[rt][t][score_gained] = fb.infeasible_marker\n",
    "\n",
    "        ## policy iteration\n",
    "        for round_index in range(iteration_round_limit):\n",
    "\n",
    "            ## policy evaluation\n",
    "            rt = 3\n",
    "            score_gained = 0\n",
    "            score_max_turn = min(score_state-2, 3*fb.maxhitscore)\n",
    "            # if score_state==63:\n",
    "            #     print('lol')\n",
    "            prob_turn_transit = solve_turn_transit_probability_fast_t(score_state, state_action, t, prob_normalscore_nt, prob_normalscore_t, prob_grid_doublescore_nt,prob_grid_doublescore_t, prob_grid_bullscore_nt, prob_grid_bullscore_t, prob_bust_dic_nt, prob_bust_dic_t)\n",
    "            turn_transit_list[score_state].append(prob_turn_transit.copy())\n",
    "            prob_turn_zeroscore = prob_turn_transit['bust'] + prob_turn_transit['score'][0][0]\n",
    "            tokens_turn = min(3,max(0,t-(3)))\n",
    "            new_value_rt3 = 1 \n",
    "            for temp in range(tokens_turn+1): \n",
    "                new_value_rt3 += np.dot(prob_turn_transit['score'][temp][1:], np.transpose(optimal_value_rt3[t-temp][score_state-1:score_state-score_max_turn-1:-1])) \n",
    "            new_value_rt3 = new_value_rt3 / (1-prob_turn_zeroscore)\n",
    "            state_value_update[rt][t][score_gained] = new_value_rt3\n",
    "            optimal_value_rt3[t,score_state] = new_value_rt3\n",
    "            #print('evaluate rt3 value= {}'.format(new_value_rt3)\n",
    "\n",
    "            ## policy improvement\n",
    "            for rt in [1,2,3]:            \n",
    "                this_throw_state_len = state_len_vector[rt]\n",
    "                tokens_turn = min(3,max(0,t-(3-rt)))\n",
    "                \n",
    "                ## state which can not bust.  score_state-score_gained>=62 \n",
    "                state_notbust_len =  max(min(score_state-61, this_throw_state_len),0)\n",
    "                if (state_notbust_len > 0):\n",
    "                    if (rt==1 and round_index==0):\n",
    "                        ## combine all non-bust states together \n",
    "                        state_notbust_update_index = state_notbust_len                    \n",
    "                        next_state_value_array = np.zeros((max_token_index, 61, state_notbust_len))                    \n",
    "                        for score_gained in range(state_notbust_len):\n",
    "                            ## skip infeasible state\n",
    "                            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                                continue\n",
    "                            score_remain = score_state - score_gained\n",
    "                            score_max = 60 ## always 60 here\n",
    "                            score_max_plus1 = score_max + 1\n",
    "                            next_state_value_array[:t+1,:,score_gained] = optimal_value_rt3[:t+1,score_remain:score_remain-score_max_plus1:-1]\n",
    "                    elif (rt==2 and (round_index==0 or score_state<182)):\n",
    "                        ## combine all non-bust states together \n",
    "                        state_notbust_update_index = state_notbust_len\n",
    "                        next_state_value_array = np.zeros((max_token_index, 61, state_notbust_len))                    \n",
    "                        for score_gained in range(state_notbust_len):\n",
    "                            ## skip infeasible state\n",
    "                            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                                continue\n",
    "                            score_remain = score_state - score_gained\n",
    "                            score_max = 60 ## always 60 here\n",
    "                            score_max_plus1 = score_max + 1\n",
    "                            next_state_value_array[:t+1,:,score_gained] = state_value_update[rt-1][:t+1,score_gained:score_gained+score_max_plus1]\n",
    "                    else: ##(rt==1 and round_index>0) or (rt==2 and round_index>0 and score_state>=182) or (rt==3)\n",
    "                        ## only update state of score_gained = 0\n",
    "                        state_notbust_update_index = 1\n",
    "                        next_state_value_array = np.zeros((max_token_index,61))\n",
    "                        score_gained = 0\n",
    "                        score_remain = score_state - score_gained\n",
    "                        score_max = 60 ## always 60 here\n",
    "                        score_max_plus1 = score_max + 1                    \n",
    "                        ## make a copy\n",
    "                        if (rt > 1):\n",
    "                            next_state_value_array[:t+1,:] = state_value_update[rt-1][:t+1,score_gained:score_gained+score_max_plus1]\n",
    "                        ## transit to next turn when rt=1\n",
    "                        else:\n",
    "                            next_state_value_array[:t+1,:] = optimal_value_rt3[:t+1,score_remain:score_remain-score_max_plus1:-1]\n",
    "\n",
    "                    ## matrix product to compute all together\n",
    "                    next_state_value_tensor = torch.from_numpy(next_state_value_array)\n",
    "                    ## transit to next throw in the same turn when rt=3,2\n",
    "                    ## -----------TOKEN LOGIC -------------\n",
    "                    if t==0: \n",
    "                        if (rt > 1):                    \n",
    "                            num_turns_tensor = prob_normalscore_tensor_nt.matmul(next_state_value_tensor[t])\n",
    "                        ## transit to next turn when rt=1\n",
    "                        else:\n",
    "                            num_turns_tensor = 1 + prob_normalscore_tensor_nt.matmul(next_state_value_tensor[t])\n",
    "                    else: \n",
    "                        if (rt > 1):                    \n",
    "                            num_turns_tensor = prob_normalscore_tensor_nt.matmul(next_state_value_tensor[t])\n",
    "                            num_turns_tensor += prob_normalscore_tensor_t.matmul(next_state_value_tensor[t-1])\n",
    "                        ## transit to next turn when rt=1\n",
    "                        else:\n",
    "                            num_turns_tensor = 1 \n",
    "                            num_turns_tensor += prob_normalscore_tensor_nt.matmul(next_state_value_tensor[t])\n",
    "                            num_turns_tensor += prob_normalscore_tensor_t.matmul(next_state_value_tensor[t-1])\n",
    "\n",
    "                    ## searching\n",
    "                    temp1 = num_turns_tensor.min(axis=0)                \n",
    "                    state_action_update[rt][t][0:state_notbust_update_index] = temp1.indices.numpy()\n",
    "                    state_value_update[rt][t][0:state_notbust_update_index] =  temp1.values.numpy()                \n",
    "                \n",
    "                ## state which possibly bust.  score_state-score_gained<62 \n",
    "                if (state_notbust_len < this_throw_state_len):\n",
    "                    ## combine all bust states together \n",
    "                    state_bust_len = this_throw_state_len - state_notbust_len\n",
    "                    next_state_value_array = np.zeros((max_token_index,61, state_bust_len))\n",
    "                    for score_gained in range(state_notbust_len, this_throw_state_len):\n",
    "                        ## skip infeasible state\n",
    "                        if not fb.state_feasible_array[rt, score_gained]:\n",
    "                            continue\n",
    "                        score_remain = score_state - score_gained\n",
    "                        #score_max = min(score_remain-2, 60)\n",
    "                        score_max = score_remain-2 ## less than 60 here\n",
    "                        score_max_plus1 = score_max + 1\n",
    "                        score_gained_index = score_gained - state_notbust_len ## index off set\n",
    "                        if (rt > 1):\n",
    "                            next_state_value_array[:t+1,0:score_max_plus1,score_gained_index] = state_value_update[rt-1][:t+1,score_gained:score_gained+score_max_plus1]\n",
    "                        ## transit to next turn when rt=1\n",
    "                        else:\n",
    "                            next_state_value_array[:t+1,0:score_max_plus1,score_gained_index] = optimal_value_rt3[:t+1,score_remain:score_remain-score_max_plus1:-1]\n",
    "                    \n",
    "                    next_state_value_tensor = torch.from_numpy(next_state_value_array)\n",
    "                    \n",
    "                    if t==0: \n",
    "                        if (rt > 1):                    \n",
    "                            num_turns_tensor = prob_normalscore_tensor_nt.matmul(next_state_value_tensor[t])\n",
    "                        ## transit to next turn when rt=1\n",
    "                        else:\n",
    "                            num_turns_tensor = 1 + prob_normalscore_tensor_nt.matmul(next_state_value_tensor[t])\n",
    "                    else: \n",
    "                        if (rt > 1):                    \n",
    "                            num_turns_tensor = prob_normalscore_tensor_nt.matmul(next_state_value_tensor[t])\n",
    "                            num_turns_tensor += prob_normalscore_tensor_t.matmul(next_state_value_tensor[t-1])\n",
    "                        ## transit to next turn when rt=1\n",
    "                        else:\n",
    "                            num_turns_tensor = 1 \n",
    "                            num_turns_tensor += prob_normalscore_tensor_nt.matmul(next_state_value_tensor[t])\n",
    "                            num_turns_tensor += prob_normalscore_tensor_t.matmul(next_state_value_tensor[t-1])\n",
    "\n",
    "                    ## consider bust/finishing for each bust state seperately \n",
    "                    num_turns_array = num_turns_tensor.numpy()                \n",
    "                    for score_gained in range(state_notbust_len, this_throw_state_len):\n",
    "                        ## skip infeasible state\n",
    "                        if not fb.state_feasible_array[rt, score_gained]:\n",
    "                            continue\n",
    "                        score_remain = score_state - score_gained\n",
    "                        #score_max = min(score_remain-2, 60)\n",
    "                        score_max = score_remain-2 ## less than 60 here\n",
    "                        score_max_plus1 = score_max + 1\n",
    "                        score_gained_index = score_gained - state_notbust_len\n",
    "\n",
    "                        ## transit to the end of game ---> double-check this logic \n",
    "                        if (rt > 1):\n",
    "                            if t == 0:\n",
    "                                if (score_remain == fb.score_DB):                        \n",
    "                                    num_turns_array[:,score_gained_index] += prob_DB_nt\n",
    "\n",
    "                                elif (score_remain <= 40 and score_remain%2==0):\n",
    "                                    num_turns_array[:,score_gained_index] += prob_doublescore_dic_nt[score_remain]\n",
    "                                    \n",
    "                                else:\n",
    "                                    pass\n",
    "                            else: \n",
    "                                if (score_remain == fb.score_DB):                        \n",
    "                                    num_turns_array[:,score_gained_index] += prob_DB_t + prob_DB_nt\n",
    "\n",
    "                                elif (score_remain <= 40 and score_remain%2==0):\n",
    "                                    num_turns_array[:,score_gained_index] += prob_doublescore_dic_t[score_remain] + prob_doublescore_dic_nt[score_remain]\n",
    "                                    \n",
    "                                else:\n",
    "                                    pass\n",
    "\n",
    "                        ## transit to bust\n",
    "                        if (rt==3):\n",
    "                            num_turns_array[:,score_gained_index] += prob_bust_dic_nt[score_max]\n",
    "                            ## solve an equation other than using the policy evaluation value (s,i=3,u=0)\n",
    "                            num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic_nt[score_max] \n",
    "                        elif (rt==2):\n",
    "                            num_turns_array[:,score_gained_index] += prob_bust_dic_nt[score_max]*(1+new_value_rt3)\n",
    "                        else:\n",
    "                            num_turns_array[:,score_gained_index] += prob_bust_dic_nt[score_max]*(new_value_rt3)  ## 1 turn is already counted before\n",
    "\n",
    "                    ## searching\n",
    "                    temp1 = num_turns_tensor.min(axis=0)\n",
    "                    state_action_update[rt][t][state_notbust_len:this_throw_state_len] = temp1.indices.numpy()\n",
    "                    state_value_update[rt][t][state_notbust_len:this_throw_state_len] =  temp1.values.numpy()                \n",
    "\n",
    "                #### finish rt=1,2,3. check improvement\n",
    "                action_diff[rt][t][:] = np.abs(state_action_update[rt][t] - state_action[rt][t])                                \n",
    "                value_relerror[rt][t] = np.abs((state_value_update[rt][t] - state_value[rt][t])/state_value_update[rt][t]).max()\n",
    "                state_action[rt][t][:] = state_action_update[rt][t][:]\n",
    "                state_value[rt][t][:] = state_value_update[rt][t][:]\n",
    "\n",
    "            max_action_diff = max([action_diff[1].max(), action_diff[2].max(), action_diff[3].max()])\n",
    "            max_value_relerror = value_relerror.max()            \n",
    "            \n",
    "            if (max_action_diff < 1):\n",
    "            #if max_value_relerror < iteration_relerror_limit:\n",
    "                num_iteration_record[score_state] = round_index + 1\n",
    "                break\n",
    "\n",
    "        for rt in [1,2,3]:\n",
    "            state_value_update[rt][t][fb.state_infeasible[rt]] = fb.largenumber\n",
    "            state_action_update[rt][t][fb.state_infeasible[rt]] = fb.infeasible_marker\n",
    "        optimal_action_index_dic[score_state] = ft.copy_numberarray_container(state_action_update)\n",
    "        optimal_value_dic[score_state] = ft.copy_numberarray_container(state_value_update, new_dtype=fb.result_float_dytpe)\n",
    "        optimal_value_rt3[0,score_state] = state_value[3][0]\n",
    "        ## done:V(s,i=3/2/1,u)\n",
    "\n",
    "##\n",
    "prob_scorestate_transit = {}    \n",
    "prob_scorestate_transit =  solve_policy_transit_probability_nt(optimal_action_index_dic, prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore)\n",
    "t2 = time.time()\n",
    "print('solve dp_turn_policyiter in {} seconds'.format(t2-t1))\n",
    "\n",
    "print(optimal_value_rt3)\n",
    "result_dic = {'optimal_value_dic':optimal_value_dic, 'optimal_action_index_dic':optimal_action_index_dic, 'optimal_value_rt3':optimal_value_rt3, 'prob_scorestate_transit':prob_scorestate_transit}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2856e-28, 6.6976e-16, 1.8152e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_DB_combined = np.zeros(len(prob_DB_nt))\n",
    "prob_DB_combined[:throw_num] += prob_DB_nt[:throw_num]\n",
    "prob_DB_combined[throw_num:] += prob_DB_nt[throw_num:]\n",
    "prob_DB_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_DB_nt.argmax()\n",
    "prob_DB_nt[750]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DB'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_DB_t.argmax()\n",
    "prob_DB_t[748:752]\n",
    "a_list[750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S20'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list[throw_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "throw_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 61)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_value_update[rt-1][:t+1,score_gained:score_gained+score_max_plus1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.    ],\n",
       "       [1.    ],\n",
       "       [1.    ],\n",
       "       ...,\n",
       "       [2.6622],\n",
       "       [2.6622],\n",
       "       [2.6622]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_turns_array.shape "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check for Noturn Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachael/Desktop/OptimalDarts-main/function_solve_dp_tokens.py:174: RuntimeWarning: overflow encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n"
     ]
    }
   ],
   "source": [
    "[noturn_optimal_value, noturn_optimal_action_index] = fsdt.solve_dp_noturn_tokens(aiming_grid, prob_grid_normalscore_nt, prob_grid_normalscore_t, tokens = tokens, prob_grid_doublescore=prob_grid_doublescore_nt, prob_grid_bullscore=prob_grid_bullscore_nt,prob_grid_doublescore_t=prob_grid_doublescore_t, prob_grid_bullscore_t=prob_grid_bullscore_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_turn_transit_probability_fast(score_state, state_action, prob_normalscore, prob_doublescore, prob_bullscore, prob_bust_dic):\n",
    "    \"\"\"\n",
    "    A fast way of implementing solve_turn_transit_probability by using pre-stored prob_bust_dic\n",
    "    \"\"\"     \n",
    "    \n",
    "    result_dict = {}\n",
    "    prob_finish = 0 ## probability of finishing the game\n",
    "    prob_bust_total = 0   ## probability of busting the game\n",
    "    ## initialize for (s, rt=3, score_gained=0)\n",
    "    next_throw_state_len = 1\n",
    "    prob_transit_next_throw_state = np.ones(next_throw_state_len)\n",
    "    \n",
    "    for rt in [3,2,1]:\n",
    "        prob_this_throw_state = prob_transit_next_throw_state\n",
    "        this_throw_state_len = next_throw_state_len\n",
    "        next_throw_state_len = min(score_state-2, fb.maxhitscore*(4-rt)) + 1\n",
    "        prob_transit_next_throw_state = np.zeros(next_throw_state_len)  ## probability vector of total score_gained after this throw\n",
    "        \n",
    "        prob_normalscore_transit = prob_normalscore[state_action[rt][0:this_throw_state_len]]*prob_this_throw_state.reshape((this_throw_state_len,1))\n",
    "        \n",
    "        for score_gained in range(this_throw_state_len):  # loop through score already gained\n",
    "            ## skip infeasible state\n",
    "            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                continue   \n",
    "\n",
    "            ## aimming location of the policy at this state\n",
    "            aiming_location_index = state_action[rt][score_gained]\n",
    "            prob_this_state = prob_this_throw_state[score_gained]\n",
    "            \n",
    "            #largest possible normal socre to make in the next throw without busting\n",
    "            score_remain = score_state - score_gained\n",
    "            score_max = min(score_remain-2, 60)\n",
    "            score_max_plus1 = score_max + 1\n",
    "        \n",
    "            ## transit to next throw or turn with normal scores            \n",
    "            prob_transit_next_throw_state[score_gained:score_gained+score_max_plus1] += prob_normalscore_transit[score_gained, 0:score_max_plus1]\n",
    "            ## game can not bust or end when score_max = 60, i.e.,  prob_notbust = 1\n",
    "            if (score_max < 60):\n",
    "                ## transit to the end of game\n",
    "                if (score_remain == fb.score_DB):\n",
    "                    prob_finish += prob_bullscore[aiming_location_index, 1]*prob_this_state\n",
    "                elif (score_remain <= 40 and score_remain%2==0):\n",
    "                    doublescore_index = (score_remain//2) - 1\n",
    "                    prob_finish += prob_doublescore[aiming_location_index, doublescore_index]*prob_this_state\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                #transit to bust\n",
    "                prob_bust_total += prob_bust_dic[score_max][aiming_location_index]*prob_this_state\n",
    "            \n",
    "    result_dict['finish'] = prob_finish\n",
    "    result_dict['bust'] = prob_bust_total\n",
    "    result_dict['score'] = prob_transit_next_throw_state\n",
    "\n",
    "    return result_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachael/Desktop/OptimalDarts-main/function_solve_dp_tokens.py:82: RuntimeWarning: divide by zero encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n",
      "/Users/rachael/Desktop/OptimalDarts-main/function_solve_dp_tokens.py:82: RuntimeWarning: overflow encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/636321877.py:215: RuntimeWarning: divide by zero encountered in divide\n",
      "  num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic[score_max]\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/636321877.py:215: RuntimeWarning: overflow encountered in divide\n",
      "  num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic[score_max]\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/636321877.py:228: RuntimeWarning: divide by zero encountered in divide\n",
      "  value_relerror[rt] = np.abs((state_value_update[rt] - state_value[rt])/state_value_update[rt]).max()\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/636321877.py:228: RuntimeWarning: invalid value encountered in divide\n",
      "  value_relerror[rt] = np.abs((state_value_update[rt] - state_value[rt])/state_value_update[rt]).max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solve prob_policy_transit in 0.24787569046020508 seconds\n",
      "solve dp_turn_policyiter in 1.7931010723114014 seconds\n",
      "[0.     0.     1.4381 ... 5.0818 5.0845 5.0965]\n"
     ]
    }
   ],
   "source": [
    "## aiming_grid\n",
    "num_aiming_location = aiming_grid.shape[0]\n",
    "prob_normalscore = prob_grid_normalscore\n",
    "prob_doublescore_dic = {}\n",
    "for doublescore_index in range(20):\n",
    "    doublescore = 2*(doublescore_index+1)\n",
    "    prob_doublescore_dic[doublescore] = np.array(prob_grid_doublescore[:,doublescore_index])\n",
    "prob_DB = np.array(prob_grid_bullscore[:,1])\n",
    "\n",
    "## the probability of not bust for each action given score_max=i (score_remain=i+2)\n",
    "prob_bust_dic = {}\n",
    "prob_notbust_dic = {}\n",
    "for score_max in range(60):    \n",
    "    ## transit to next throw or turn\n",
    "    prob_notbust = prob_grid_normalscore[:,0:score_max+1].sum(axis=1)\n",
    "    ## transit to the end of game\n",
    "    score_remain = score_max + 2\n",
    "    if (score_remain == fb.score_DB):\n",
    "        prob_notbust += prob_DB\n",
    "    elif (score_remain <= 40 and score_remain%2==0):\n",
    "        prob_notbust += prob_doublescore_dic[score_remain]\n",
    "    ##\n",
    "    prob_notbust = np.minimum(np.maximum(prob_notbust, 0),1)\n",
    "    prob_notbust_dic[score_max] = prob_notbust\n",
    "    prob_bust_dic[score_max] = 1 - prob_notbust_dic[score_max]\n",
    "\n",
    "prob_normalscore_tensor = torch.from_numpy(prob_normalscore)\n",
    "\n",
    "iteration_round_limit = 20\n",
    "iteration_relerror_limit = 10**-9\n",
    "\n",
    "#### state space example of (SB=25 DB=50) ####\n",
    "## rt: the number of remaining throws in a turn\n",
    "## state_infeasible_rt2 = [23, 29, 31, 35, 37, 41, 43, 44, 46, 47, 49, 52, 53, 55, 56, 58, 59]\n",
    "## state_infeasible_rt1 = [103, 106, 109, 112, 113, 115, 116, 118, 119]    \n",
    "    \n",
    "optimal_value_rt3 = np.zeros(502) #vector: optimal value for the beginning state of each turn (rt=3)\n",
    "optimal_value_dic = {} ## first key: score=0,2,...,501, second key: remaining throws=3,2,1\n",
    "optimal_action_index_dic = {}\n",
    "num_iteration_record = np.zeros(502, dtype=np.int32)\n",
    "\n",
    "state_len_vector = np.zeros(4, dtype=np.int32)\n",
    "state_value  = [None]  ## optimal value (expected # of turns to finish the game) for each state in the current playing turn\n",
    "state_action = [None]  ## aimming locations for for each state in the current playing turn\n",
    "action_diff  = [None]\n",
    "value_relerror = np.zeros(4)\n",
    "for rt in [1,2,3]:\n",
    "    ## for rt=3: possible score_gained = 0\n",
    "    ## for rt=2: possible score_gained = 0,1,...,60\n",
    "    ## for rt=1: possible score_gained = 0,1,...,120\n",
    "    this_throw_state_len = fb.maxhitscore*(3-rt) + 1\n",
    "    state_value.append(np.ones(this_throw_state_len)*fb.largenumber)\n",
    "    state_action.append(np.ones(this_throw_state_len, np.int32)*fb.infeasible_marker)\n",
    "    action_diff.append(np.ones(this_throw_state_len))\n",
    "state_value_update = ft.copy_numberarray_container(state_value)\n",
    "state_action_update = ft.copy_numberarray_container(state_action)\n",
    "\n",
    "## use no_turn policy as the initial policy\n",
    "[noturn_optimal_value, noturn_optimal_action_index] = fsdt.solve_dp_noturn(aiming_grid, prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore)\n",
    "\n",
    "t1 = time.time()\n",
    "for score_state in range(2, 502):\n",
    "    #print('#### solve_dp_turn score_state={} ####'.format(score_state))    \n",
    "    \n",
    "    ## initialization \n",
    "    for rt in [1,2,3]:\n",
    "        ## for rt=3: score_gained = 0\n",
    "        ## for rt=2: score_gained = 0,1,...,min(s-2,60)\n",
    "        ## for rt=1: score_gained = 0,1,...,min(s-2,120)\n",
    "        this_throw_state_len = min(score_state-2, fb.maxhitscore*(3-rt)) + 1\n",
    "        state_len_vector[rt] = this_throw_state_len\n",
    "                \n",
    "        ## initialize the starting policy: \n",
    "        ## use no_turn action in (s, i, u=0)\n",
    "        ## use turn action (s-1, i, u-1) in (s, i, u!=0) if (s-1, i, u-1) is feasible state\n",
    "        state_action[rt][0] = noturn_optimal_action_index[score_state]            \n",
    "        for score_gained in range(1,this_throw_state_len):                \n",
    "            if fb.state_feasible_array[rt, score_gained]:  ## if True\n",
    "                if fb.state_feasible_array[rt, score_gained-1]:\n",
    "                    state_action[rt][score_gained] = optimal_action_index_dic[score_state-1][rt][score_gained-1]\n",
    "                else:                        \n",
    "                    state_action[rt][score_gained] = noturn_optimal_action_index[score_state-score_gained]\n",
    "            else:\n",
    "                state_action[rt][score_gained] = fb.infeasible_marker\n",
    "\n",
    "    ## policy iteration\n",
    "    for round_index in range(iteration_round_limit):\n",
    "\n",
    "        ## policy evaluation\n",
    "        rt = 3\n",
    "        score_gained = 0\n",
    "        score_max_turn = min(score_state-2, 3*fb.maxhitscore)\n",
    "        prob_turn_transit = solve_turn_transit_probability_fast(score_state, state_action, prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore, prob_bust_dic)        \n",
    "        prob_turn_zeroscore = prob_turn_transit['bust'] + prob_turn_transit['score'][0]\n",
    "        new_value_rt3 = (1 + np.dot(prob_turn_transit['score'][1:], optimal_value_rt3[score_state-1:score_state-score_max_turn-1:-1])) / (1-prob_turn_zeroscore)\n",
    "        state_value_update[rt][score_gained] = new_value_rt3\n",
    "        optimal_value_rt3[score_state] = new_value_rt3\n",
    "        #print('evaluate rt3 value= {}'.format(new_value_rt3)\n",
    "\n",
    "        ## policy improvement\n",
    "        for rt in [1,2,3]:            \n",
    "            this_throw_state_len = state_len_vector[rt]\n",
    "            \n",
    "            ## state which can not bust.  score_state-score_gained>=62 \n",
    "            state_notbust_len =  max(min(score_state-61, this_throw_state_len),0)\n",
    "            if (state_notbust_len > 0):\n",
    "                if (rt==1 and round_index==0):\n",
    "                    ## combine all non-bust states together \n",
    "                    state_notbust_update_index = state_notbust_len                    \n",
    "                    next_state_value_array = np.zeros((61, state_notbust_len))                    \n",
    "                    for score_gained in range(state_notbust_len):\n",
    "                        ## skip infeasible state\n",
    "                        if not fb.state_feasible_array[rt, score_gained]:\n",
    "                            continue\n",
    "                        score_remain = score_state - score_gained\n",
    "                        score_max = 60 ## always 60 here\n",
    "                        score_max_plus1 = score_max + 1\n",
    "                        next_state_value_array[:,score_gained] = optimal_value_rt3[score_remain:score_remain-score_max_plus1:-1]\n",
    "                elif (rt==2 and (round_index==0 or score_state<182)):\n",
    "                    ## combine all non-bust states together \n",
    "                    state_notbust_update_index = state_notbust_len\n",
    "                    next_state_value_array = np.zeros((61, state_notbust_len))                    \n",
    "                    for score_gained in range(state_notbust_len):\n",
    "                        ## skip infeasible state\n",
    "                        if not fb.state_feasible_array[rt, score_gained]:\n",
    "                            continue\n",
    "                        score_remain = score_state - score_gained\n",
    "                        score_max = 60 ## always 60 here\n",
    "                        score_max_plus1 = score_max + 1\n",
    "                        next_state_value_array[:,score_gained] = state_value_update[rt-1][score_gained:score_gained+score_max_plus1]\n",
    "                else: ##(rt==1 and round_index>0) or (rt==2 and round_index>0 and score_state>=182) or (rt==3)\n",
    "                    ## only update state of score_gained = 0\n",
    "                    state_notbust_update_index = 1\n",
    "                    next_state_value_array = np.zeros(61)\n",
    "                    score_gained = 0\n",
    "                    score_remain = score_state - score_gained\n",
    "                    score_max = 60 ## always 60 here\n",
    "                    score_max_plus1 = score_max + 1                    \n",
    "                    ## make a copy\n",
    "                    if (rt > 1):\n",
    "                        next_state_value_array[:] = state_value_update[rt-1][score_gained:score_gained+score_max_plus1]\n",
    "                    ## transit to next turn when rt=1\n",
    "                    else:\n",
    "                        next_state_value_array[:] = optimal_value_rt3[score_remain:score_remain-score_max_plus1:-1]\n",
    "\n",
    "                ## matrix product to compute all together\n",
    "                next_state_value_tensor = torch.from_numpy(next_state_value_array)\n",
    "                ## transit to next throw in the same turn when rt=3,2\n",
    "                if (rt > 1):                    \n",
    "                    num_turns_tensor = prob_normalscore_tensor.matmul(next_state_value_tensor)\n",
    "                ## transit to next turn when rt=1\n",
    "                else:\n",
    "                    num_turns_tensor = 1 + prob_normalscore_tensor.matmul(next_state_value_tensor)\n",
    "\n",
    "                ## searching\n",
    "                temp1 = num_turns_tensor.min(axis=0)                \n",
    "                state_action_update[rt][0:state_notbust_update_index] = temp1.indices.numpy()\n",
    "                state_value_update[rt][0:state_notbust_update_index] =  temp1.values.numpy()                \n",
    "            \n",
    "            ## state which possibly bust.  score_state-score_gained<62 \n",
    "            if (state_notbust_len < this_throw_state_len):\n",
    "                ## combine all bust states together \n",
    "                state_bust_len = this_throw_state_len - state_notbust_len\n",
    "                next_state_value_array = np.zeros((61, state_bust_len))\n",
    "                for score_gained in range(state_notbust_len, this_throw_state_len):\n",
    "                    ## skip infeasible state\n",
    "                    if not fb.state_feasible_array[rt, score_gained]:\n",
    "                        continue\n",
    "                    score_remain = score_state - score_gained\n",
    "                    #score_max = min(score_remain-2, 60)\n",
    "                    score_max = score_remain-2 ## less than 60 here\n",
    "                    score_max_plus1 = score_max + 1\n",
    "                    score_gained_index = score_gained - state_notbust_len ## index off set\n",
    "                    if (rt > 1):\n",
    "                        next_state_value_array[0:score_max_plus1,score_gained_index] = state_value_update[rt-1][score_gained:score_gained+score_max_plus1]\n",
    "                    ## transit to next turn when rt=1\n",
    "                    else:\n",
    "                        next_state_value_array[0:score_max_plus1,score_gained_index] = optimal_value_rt3[score_remain:score_remain-score_max_plus1:-1]\n",
    "                \n",
    "                next_state_value_tensor = torch.from_numpy(next_state_value_array)\n",
    "                ## transit to next throw in the same turn when rt=3,2\n",
    "                if (rt > 1):                    \n",
    "                    num_turns_tensor = prob_normalscore_tensor.matmul(next_state_value_tensor)\n",
    "                ## transit to next turn when rt=1\n",
    "                else:\n",
    "                    num_turns_tensor = 1 + prob_normalscore_tensor.matmul(next_state_value_tensor)                                                               \n",
    "\n",
    "                ## consider bust/finishing for each bust state seperately \n",
    "                num_turns_array = num_turns_tensor.numpy()                \n",
    "                for score_gained in range(state_notbust_len, this_throw_state_len):\n",
    "                    ## skip infeasible state\n",
    "                    if not fb.state_feasible_array[rt, score_gained]:\n",
    "                        continue\n",
    "                    score_remain = score_state - score_gained\n",
    "                    #score_max = min(score_remain-2, 60)\n",
    "                    score_max = score_remain-2 ## less than 60 here\n",
    "                    score_max_plus1 = score_max + 1\n",
    "                    score_gained_index = score_gained - state_notbust_len\n",
    "\n",
    "                    ## transit to the end of game\n",
    "                    if (rt > 1):\n",
    "                        if (score_remain == fb.score_DB):                        \n",
    "                            num_turns_array[:,score_gained_index] += prob_DB\n",
    "                        elif (score_remain <= 40 and score_remain%2==0):\n",
    "                            num_turns_array[:,score_gained_index] += prob_doublescore_dic[score_remain]\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                    ## transit to bust\n",
    "                    if (rt==3):\n",
    "                        num_turns_array[:,score_gained_index] += prob_bust_dic[score_max]\n",
    "                        ## solve an equation other than using the policy evaluation value (s,i=3,u=0)\n",
    "                        num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic[score_max] \n",
    "                    elif (rt==2):\n",
    "                        num_turns_array[:,score_gained_index] += prob_bust_dic[score_max]*(1+new_value_rt3)\n",
    "                    else:\n",
    "                        num_turns_array[:,score_gained_index] += prob_bust_dic[score_max]*(new_value_rt3)  ## 1 turn is already counted before\n",
    "\n",
    "                ## searching\n",
    "                temp1 = num_turns_tensor.min(axis=0)\n",
    "                state_action_update[rt][state_notbust_len:this_throw_state_len] = temp1.indices.numpy()\n",
    "                state_value_update[rt][state_notbust_len:this_throw_state_len] =  temp1.values.numpy()                \n",
    "\n",
    "            #### finish rt=1,2,3. check improvement\n",
    "            action_diff[rt][:] = np.abs(state_action_update[rt] - state_action[rt])                                \n",
    "            value_relerror[rt] = np.abs((state_value_update[rt] - state_value[rt])/state_value_update[rt]).max()\n",
    "            state_action[rt][:] = state_action_update[rt][:]\n",
    "            state_value[rt][:] = state_value_update[rt][:]\n",
    "\n",
    "        max_action_diff = max([action_diff[1].max(), action_diff[2].max(), action_diff[3].max()])\n",
    "        max_value_relerror = value_relerror.max()            \n",
    "        \n",
    "        if (max_action_diff < 1):\n",
    "        #if max_value_relerror < iteration_relerror_limit:\n",
    "            num_iteration_record[score_state] = round_index + 1\n",
    "            break\n",
    "\n",
    "    for rt in [1,2,3]:\n",
    "        state_value_update[rt][fb.state_infeasible[rt]] = fb.largenumber\n",
    "        state_action_update[rt][fb.state_infeasible[rt]] = fb.infeasible_marker\n",
    "    optimal_action_index_dic[score_state] = ft.copy_numberarray_container(state_action_update)\n",
    "    optimal_value_dic[score_state] = ft.copy_numberarray_container(state_value_update, new_dtype=fb.result_float_dytpe)\n",
    "    optimal_value_rt3[score_state] = state_value[3][0]\n",
    "    ## done:V(s,i=3/2/1,u)\n",
    "\n",
    "##\n",
    "prob_scorestate_transit = {}    \n",
    "prob_scorestate_transit =  fep.solve_policy_transit_probability(optimal_action_index_dic, prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore)\n",
    "t2 = time.time()\n",
    "print('solve dp_turn_policyiter in {} seconds'.format(t2-t1))\n",
    "\n",
    "print(optimal_value_rt3)\n",
    "result_dic = {'optimal_value_dic':optimal_value_dic, 'optimal_action_index_dic':optimal_action_index_dic, 'optimal_value_rt3':optimal_value_rt3, 'prob_scorestate_transit':prob_scorestate_transit}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9934, 1.    , 1.    , ..., 1.    , 1.    , 1.    ])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_notbust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8a57194bbeb03cec992a62989c4918360c5f4e4ce600e16b9e817797d129cef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
