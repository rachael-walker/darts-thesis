{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_pickle from ./data_parameter/player_gaussin_fit/grid_custom_no_tokens/player10_gaussin_prob_grid_custom_no_tokens.pkl\n",
      "load_pickle from ./data_parameter/player_gaussin_fit/grid_custom_no_tokens/player10_gaussin_prob_grid_custom_no_tokens.pkl\n",
      "load_pickle from ./data_parameter/player_gaussin_fit/grid_custom_tokens/player10_gaussin_prob_grid_custom_tokens.pkl\n"
     ]
    }
   ],
   "source": [
    "import init_load_board\n",
    "exec(open('init_load_board.py').read())\n",
    "\n",
    "import init_simple_mdp\n",
    "exec(open('init_simple_mdp.py').read())\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import function_board as fb \n",
    "import function_tool as ft\n",
    "import function_get_aiming_grid \n",
    "exec(open('function_get_aiming_grid.py').read())\n",
    "\n",
    "import evaluate_score_probability_with_error as esp\n",
    "import function_solve_dp\n",
    "\n",
    "#%%\n",
    "data_parameter_dir = fb.data_parameter_dir\n",
    "result_dir = './result'       \n",
    "\n",
    "\n",
    "\n",
    "a_throw_list = []\n",
    "a_token_list = []\n",
    "\n",
    "for a in actions:\n",
    "    a_throw_list.append(a)\n",
    "\n",
    "for a in token_actions:\n",
    "    a_token_list.append(a)\n",
    "\n",
    "a_list = a_throw_list + a_token_list\n",
    "throw_num = len(a_throw_list)\n",
    "\n",
    "name_pa = 'player{}'.format(10)\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import function_board as fb\n",
    "import function_tool as ft\n",
    "import function_get_aiming_grid\n",
    "import function_evaluate_policy as fep\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(linewidth=300)\n",
    "np.set_printoptions(threshold=300)\n",
    "\n",
    "import torch\n",
    "torch.set_printoptions(precision=4)\n",
    "torch.set_printoptions(linewidth=300)\n",
    "torch.set_printoptions(threshold=300)\n",
    "\n",
    "[aiming_grid, prob_grid_normalscore, prob_grid_singlescore, prob_grid_doublescore, prob_grid_triplescore, prob_grid_bullscore] = function_get_aiming_grid.load_aiming_grid(name_pa, data_parameter_dir=data_parameter_dir, grid_version='custom_no_tokens')\n",
    "\n",
    "[aiming_grid, prob_grid_normalscore_nt, prob_grid_singlescore_nt, prob_grid_doublescore_nt, prob_grid_triplescore_nt, prob_grid_bullscore_nt] = function_get_aiming_grid.load_aiming_grid(name_pa, data_parameter_dir=data_parameter_dir, grid_version='custom_no_tokens')\n",
    "[aiming_grid, prob_grid_normalscore_t, prob_grid_singlescore_t, prob_grid_doublescore_t, prob_grid_triplescore_t, prob_grid_bullscore_t] = function_get_aiming_grid.load_aiming_grid(name_pa, data_parameter_dir=data_parameter_dir, grid_version='custom_tokens')\n",
    "\n",
    "import function_solve_dp_tokens as fsdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #prob_notbust\n",
    "# prob_notbust = np.zeros(len(prob_grid_normalscore_nt[:,0]))\n",
    "# prob_notbust[:throw_num] += prob_grid_normalscore_nt[:throw_num,0:4+1].sum(axis=1)\n",
    "# prob_notbust[:throw_num] += prob_grid_normalscore_t[throw_num:,0:4+1].sum(axis=1)\n",
    "\n",
    "# prob_notbust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_turn_transit_probability_nt(score_state, state_action, prob_normalscore, prob_doublescore, prob_bullscore):\n",
    "    \"\"\"\n",
    "    Solve the state transition probability after a turn playing with a specified aiming policy\n",
    "    \n",
    "    Args: \n",
    "        score_state: score at the beginning of the turn, e.g., 2,3,...,501 \n",
    "        state_action: a dict of aiming locations (actions in the policy) for each state (s,i,u) in this turn\n",
    "        prob_normalscore, prob_doublescore, prob_bullscore: the skill model \n",
    "    \n",
    "    Returns: A dict\n",
    "        result_dict['finish']: probability of finishing the game (reach zero by making a double)\n",
    "        result_dict['bust']: probability of busting the game (transit to next turn of (s=score_state,i=3,u=0))\n",
    "        result_dict['score']: probability of achieving a cumulative score_gained in this turn (transit to next turn of (s=score_state-score_gained,i=3,u=0))\n",
    "    \"\"\"    \n",
    "    \n",
    "    ##\n",
    "    result_dict = {}\n",
    "    prob_finish = 0 ## probability of finishing the game\n",
    "    prob_bust = 0   ## probability of busting the game\n",
    "    ## initialize for (s, rt=3, score_gained=0)\n",
    "    next_throw_state_len = 1\n",
    "    prob_transit_next_throw_state = np.ones(next_throw_state_len)\n",
    "    \n",
    "    for rt in [3,2,1]:\n",
    "        prob_this_throw_state = prob_transit_next_throw_state\n",
    "        this_throw_state_len = next_throw_state_len\n",
    "        next_throw_state_len = min(score_state-2, fb.maxhitscore*(4-rt)) + 1\n",
    "        prob_transit_next_throw_state = np.zeros(next_throw_state_len)  ## probability vector of total score_gained after this throw\n",
    "        \n",
    "        for score_gained in range(this_throw_state_len):\n",
    "            ## skip infeasible state\n",
    "            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                continue   \n",
    "\n",
    "            ## aimming location of the policy at this state\n",
    "            aiming_location_index = state_action[rt][0][score_gained]\n",
    "            prob_this_state = prob_this_throw_state[score_gained]\n",
    "            \n",
    "            #largest possible normal socre to make in the next throw without busting\n",
    "            score_remain = score_state - score_gained\n",
    "            score_max = min(score_remain-2, 60)\n",
    "            score_max_plus1 = score_max + 1\n",
    "        \n",
    "            ## transit to next throw or turn with normal scores\n",
    "            prob_transit_next_throw_state[score_gained:score_gained+score_max_plus1] += prob_normalscore[aiming_location_index, 0:score_max_plus1]*prob_this_state\n",
    "            ## game can not bust or end when score_max = 60, i.e.,  prob_notbust = 1\n",
    "            if (score_max < 60):\n",
    "                prob_notbust_this_state = prob_normalscore[aiming_location_index, 0:score_max+1].sum()\n",
    "                ## transit to the end of game\n",
    "                if (score_remain == fb.score_DB):\n",
    "                    prob_finish += prob_bullscore[aiming_location_index, 1]*prob_this_state\n",
    "                    prob_notbust_this_state += prob_bullscore[aiming_location_index, 1]\n",
    "                elif (score_remain <= 40 and score_remain%2==0):\n",
    "                    doublescore_index = (score_remain//2) - 1\n",
    "                    prob_finish += prob_doublescore[aiming_location_index, doublescore_index]*prob_this_state\n",
    "                    prob_notbust_this_state += prob_doublescore[aiming_location_index, doublescore_index]\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                ## transit to bust\n",
    "                prob_bust += (max(1 - prob_notbust_this_state,0))*prob_this_state\n",
    "            \n",
    "    result_dict['finish'] = prob_finish\n",
    "    result_dict['bust'] = prob_bust\n",
    "    result_dict['score'] = prob_transit_next_throw_state\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_turn_transit_probability_fast_nt(score_state, state_action, prob_normalscore_nt, prob_normalscore_t, prob_doublescore_nt,prob_doublescore_t, prob_bullscore_nt, prob_bullscore_t, prob_bust_dic_nt, prob_bust_dic_t):\n",
    "    \"\"\"\n",
    "    A fast way of implementing solve_turn_transit_probability by using pre-stored prob_bust_dic\n",
    "    \"\"\"     \n",
    "    \n",
    "    result_dict = {}\n",
    "    prob_finish = 0 ## probability of finishing the game\n",
    "    prob_bust_total = 0   ## probability of busting the game\n",
    "    ## initialize for (s, rt=3, score_gained=0)\n",
    "    next_throw_state_len = 1\n",
    "    prob_transit_next_throw_state = np.ones(next_throw_state_len)\n",
    "    \n",
    "    for rt in [3,2,1]:\n",
    "        prob_this_throw_state = prob_transit_next_throw_state\n",
    "        this_throw_state_len = next_throw_state_len\n",
    "        next_throw_state_len = min(score_state-2, fb.maxhitscore*(4-rt)) + 1\n",
    "        prob_transit_next_throw_state = np.zeros(next_throw_state_len)  ## probability vector of total score_gained after this throw\n",
    "        \n",
    "        prob_normalscore_transit = prob_normalscore_nt[state_action[rt][0][0:this_throw_state_len]]*prob_this_throw_state.reshape((this_throw_state_len,1))\n",
    "        \n",
    "        for score_gained in range(this_throw_state_len):  # loop through score already gained\n",
    "            ## skip infeasible state\n",
    "            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                continue   \n",
    "\n",
    "            ## aimming location of the policy at this state\n",
    "            aiming_location_index = state_action[rt][0][score_gained]\n",
    "            prob_this_state = prob_this_throw_state[score_gained]\n",
    "            \n",
    "            #largest possible normal socre to make in the next throw without busting\n",
    "            score_remain = score_state - score_gained\n",
    "            score_max = min(score_remain-2, 60)\n",
    "            score_max_plus1 = score_max + 1\n",
    "        \n",
    "            ## transit to next throw or turn with normal scores            \n",
    "            prob_transit_next_throw_state[score_gained:score_gained+score_max_plus1] += prob_normalscore_transit[score_gained, 0:score_max_plus1]\n",
    "            ## game can not bust or end when score_max = 60, i.e.,  prob_notbust = 1\n",
    "            if (score_max < 60):\n",
    "                ## transit to the end of game\n",
    "                if (score_remain == fb.score_DB):\n",
    "                    prob_finish += prob_bullscore_nt[aiming_location_index, 1]*prob_this_state\n",
    "                elif (score_remain <= 40 and score_remain%2==0):\n",
    "                    doublescore_index = (score_remain//2) - 1\n",
    "                    prob_finish += prob_doublescore_nt[aiming_location_index, doublescore_index]*prob_this_state\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                #transit to bust\n",
    "                prob_bust_total += prob_bust_dic_nt[score_max][aiming_location_index]*prob_this_state\n",
    "            \n",
    "    result_dict['finish'] = prob_finish\n",
    "    result_dict['bust'] = prob_bust_total\n",
    "    result_dict['score'] = prob_transit_next_throw_state\n",
    "\n",
    "    return result_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_policy_transit_probability_nt(policy_action_index_dic, prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore):\n",
    "    \"\"\"\n",
    "    For each turn, solve the state transition probability for a specified aiming policy\n",
    "    \n",
    "    Args: \n",
    "        policy_action_index_dic: a dict of aiming locations (actions in the policy) for each state (s,i,u) of each turn s=2,...,501\n",
    "        prob_normalscore, prob_doublescore, prob_bullscore: the skill model \n",
    "    \n",
    "    Returns: A dict\n",
    "    \"\"\"  \n",
    "    \n",
    "    prob_policy_transit_dict = {}\n",
    "    t1 = time.time()\n",
    "    for score_state in range(2,502):\n",
    "        prob_policy_transit_dict[score_state] = solve_turn_transit_probability_nt(score_state, policy_action_index_dic[score_state], prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore)\n",
    "\n",
    "    t2 = time.time()\n",
    "    print('solve prob_policy_transit in {} seconds'.format(t2-t1))\n",
    "    \n",
    "    return prob_policy_transit_dict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = 9\n",
    "max_token_index = tokens + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/135309105.py:288: RuntimeWarning: divide by zero encountered in divide\n",
      "  num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic_nt[score_max]\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/135309105.py:288: RuntimeWarning: overflow encountered in divide\n",
      "  num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic_nt[score_max]\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/135309105.py:301: RuntimeWarning: divide by zero encountered in divide\n",
      "  value_relerror[rt][0] = np.abs((state_value_update[rt][0] - state_value[rt][0])/state_value_update[rt][0]).max()\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/135309105.py:301: RuntimeWarning: invalid value encountered in divide\n",
      "  value_relerror[rt][0] = np.abs((state_value_update[rt][0] - state_value[rt][0])/state_value_update[rt][0]).max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solve prob_policy_transit in 0.2500011920928955 seconds\n",
      "solve dp_turn_policyiter in 9.978865146636963 seconds\n",
      "[[0.     0.     1.4381 ... 5.0818 5.0845 5.0965]\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]\n",
      " ...\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.     0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "#pzerolist = []\n",
    "turn_transit_list = {}\n",
    "## aiming_grid\n",
    "num_aiming_location = aiming_grid.shape[0]\n",
    "\n",
    "prob_normalscore_t = prob_grid_normalscore_t\n",
    "prob_doublescore_dic_t = {}\n",
    "\n",
    "prob_normalscore_nt = prob_grid_normalscore_nt\n",
    "prob_doublescore_dic_nt = {}\n",
    "\n",
    "# Initialize the probabilities of hitting a double (both for token and no token)\n",
    "for doublescore_index in range(20):\n",
    "    doublescore = 2*(doublescore_index+1)\n",
    "    # Tokens \n",
    "    doublescore_dict_array_t = np.zeros(len(prob_grid_normalscore_nt[:,0]))\n",
    "    doublescore_dict_array_t[throw_num:] = prob_grid_doublescore_t[throw_num:,doublescore_index]\n",
    "    prob_doublescore_dic_t[doublescore] = doublescore_dict_array_t\n",
    "\n",
    "    # No Tokens \n",
    "    doublescore_dict_array_nt = np.zeros(len(prob_grid_normalscore_nt[:,0]))\n",
    "    doublescore_dict_array_nt[:throw_num] = prob_grid_doublescore_t[:throw_num,doublescore_index]\n",
    "    prob_doublescore_dic_nt[doublescore] = doublescore_dict_array_nt\n",
    "\n",
    "prob_DB_nt = np.array(prob_grid_bullscore_nt[:,1])\n",
    "prob_DB_t = np.array(prob_grid_bullscore_t[:,1])\n",
    "\n",
    "## the probability of not bust for each action given score_max=i (score_remain=i+2)\n",
    "prob_bust_dic_t = {}\n",
    "prob_notbust_dic_t = {}\n",
    "\n",
    "prob_bust_dic_nt = {}\n",
    "prob_notbust_dic_nt = {}\n",
    "\n",
    "for score_max in range(60):  \n",
    "\n",
    "    ## transit to next throw or turn\n",
    "    prob_notbust_t = np.zeros(len(prob_grid_normalscore_nt[:,0]))\n",
    "    # prob_notbust_t[:throw_num] += prob_grid_normalscore_nt[:throw_num,0:score_max+1].sum(axis=1)\n",
    "    prob_notbust_t[throw_num:] += prob_grid_normalscore_t[throw_num:,0:score_max+1].sum(axis=1) \n",
    "\n",
    "    #prob_notbust_nt = np.zeros(len(prob_grid_normalscore_nt[:,0]))\n",
    "    # prob_notbust_t[:throw_num] += prob_grid_normalscore_nt[:throw_num,0:score_max+1].sum(axis=1)\n",
    "    #prob_notbust_nt[:throw_num] += prob_grid_normalscore_nt[:throw_num,0:score_max+1].sum(axis=1) \n",
    "    prob_notbust_nt = prob_grid_normalscore_nt[:,0:score_max+1].sum(axis=1) \n",
    "\n",
    "    ## transit to the end of game\n",
    "    score_remain = score_max + 2\n",
    "\n",
    "    if (score_remain == fb.score_DB):\n",
    "        prob_notbust_nt += prob_DB_nt\n",
    "        # prob_notbust_t += prob_DB_nt\n",
    "        prob_notbust_t += prob_DB_t\n",
    "    elif (score_remain <= 40 and score_remain%2==0):\n",
    "        prob_notbust_nt += prob_doublescore_dic_nt[score_remain]\n",
    "        # prob_notbust_t += prob_doublescore_dic_nt[score_remain]\n",
    "        prob_notbust_t += prob_doublescore_dic_t[score_remain]\n",
    "         \n",
    "    ## Normalize to desired probability range \n",
    "    prob_notbust_t = np.minimum(np.maximum(prob_notbust_t, 0),1)\n",
    "    prob_notbust_nt = np.minimum(np.maximum(prob_notbust_nt, 0),1)\n",
    "    \n",
    "    # Append to final dictionaries\n",
    "    prob_notbust_dic_t[score_max] = prob_notbust_t\n",
    "    prob_bust_dic_t[score_max] = 1 - prob_notbust_dic_t[score_max]\n",
    "\n",
    "    prob_notbust_dic_nt[score_max] = prob_notbust_nt\n",
    "    prob_bust_dic_nt[score_max] = 1 - prob_notbust_dic_nt[score_max]\n",
    "\n",
    "######################\n",
    "prob_bust_dic_nt = prob_bust_dic\n",
    "prob_DB_nt = prob_DB\n",
    "prob_doublescore_dic_nt = prob_doublescore_dic\n",
    "prob_normalscore_nt = prob_normalscore\n",
    "prob_notbust_dic_nt = prob_notbust_dic\n",
    "######################\n",
    "\n",
    "# Add to tensors\n",
    "prob_normalscore_tensor_nt = torch.from_numpy(prob_normalscore_nt)\n",
    "prob_normalscore_tensor_t = torch.from_numpy(prob_normalscore_t)\n",
    "\n",
    "iteration_round_limit = 20\n",
    "iteration_relerror_limit = 10**-9\n",
    "\n",
    "#### state space example of (SB=25 DB=50) ####\n",
    "## rt: the number of remaining throws in a turn\n",
    "## state_infeasible_rt2 = [23, 29, 31, 35, 37, 41, 43, 44, 46, 47, 49, 52, 53, 55, 56, 58, 59]\n",
    "## state_infeasible_rt1 = [103, 106, 109, 112, 113, 115, 116, 118, 119]    \n",
    "\n",
    "optimal_value_rt3 = np.zeros((max_token_index,502))\n",
    "optimal_value_dic = {}\n",
    "optimal_action_index_dic= {}\n",
    "\n",
    "num_iteration_record = np.zeros((max_token_index,502), dtype=np.int32)\n",
    "\n",
    "state_len_vector = np.zeros(4, dtype=np.int32)\n",
    "state_value  = [None]  ## optimal value (expected # of turns to finish the game) for each state in the current playing turn\n",
    "state_action = [None]  ## aimming locations for for each state in the current playing turn\n",
    "action_diff  = [None]\n",
    "value_relerror = np.zeros((max_token_index,4))\n",
    "\n",
    "for rt in [1,2,3]:\n",
    "\n",
    "    ## for rt=3: possible score_gained = 0\n",
    "    ## for rt=2: possible score_gained = 0,1,...,60\n",
    "    ## for rt=1: possible score_gained = 0,1,...,120\n",
    "\n",
    "    # Number of possible scores for given remaining throws (rt) in the turn\n",
    "    this_throw_state_len = fb.maxhitscore*(3-rt) + 1\n",
    "\n",
    "    # Create stacked state value, action and action diff objects \n",
    "    # Rows will be token values, columns will be remaining scores \n",
    "    state_value.append(np.ones((max_token_index,this_throw_state_len))*fb.largenumber)\n",
    "    state_action.append(np.ones((max_token_index,this_throw_state_len), np.int32)*fb.infeasible_marker)\n",
    "    action_diff.append(np.ones((max_token_index,this_throw_state_len)))\n",
    "\n",
    "# Add these to the state value update objects \n",
    "state_value_update = ft.copy_numberarray_container(state_value)\n",
    "state_action_update = ft.copy_numberarray_container(state_action)\n",
    "\n",
    "## use no_turn policy as the initial policy \n",
    "[noturn_optimal_value, noturn_optimal_action_index] = fsdt.solve_dp_noturn_tokens(aiming_grid, prob_grid_normalscore_nt, prob_grid_normalscore_t, tokens = 0, prob_grid_doublescore=prob_grid_doublescore_nt, prob_grid_bullscore=prob_grid_bullscore_nt,prob_grid_doublescore_t=prob_grid_doublescore_t, prob_grid_bullscore_t=prob_grid_bullscore_t)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for t in range(0,max_token_index):\n",
    "\n",
    "    if t==0:\n",
    "\n",
    "        for score_state in range(2, 502):\n",
    "\n",
    "            turn_transit_list[score_state] = []\n",
    "\n",
    "            # if score_state == 3:\n",
    "            #     break \n",
    "            #print('#### solve_dp_turn score_state={} ####'.format(score_state))    \n",
    "            \n",
    "            ## initialization \n",
    "            for rt in [1,2,3]:\n",
    "                ## for rt=3: score_gained = 0\n",
    "                ## for rt=2: score_gained = 0,1,...,min(s-2,60)\n",
    "                ## for rt=1: score_gained = 0,1,...,min(s-2,120)\n",
    "                this_throw_state_len = min(score_state-2, fb.maxhitscore*(3-rt)) + 1\n",
    "                state_len_vector[rt] = this_throw_state_len\n",
    "                        \n",
    "                ## initialize the starting policy: \n",
    "                ## use no_turn action in (s, i, u=0)\n",
    "                ## use turn action (s-1, i, u-1) in (s, i, u!=0) if (s-1, i, u-1) is feasible state\n",
    "                state_action[rt][0] = noturn_optimal_action_index[0,score_state]            \n",
    "                for score_gained in range(1,this_throw_state_len):                \n",
    "                    if fb.state_feasible_array[rt, score_gained]:  ## if True\n",
    "                        if fb.state_feasible_array[rt, score_gained-1]:\n",
    "                            state_action[rt][0][score_gained] = optimal_action_index_dic[score_state-1][rt][0][score_gained-1]\n",
    "                        else:                        \n",
    "                            state_action[rt][0][score_gained] = noturn_optimal_action_index[0,score_state-score_gained]\n",
    "                    else:\n",
    "                        state_action[rt][0][score_gained] = fb.infeasible_marker\n",
    "\n",
    "            ## policy iteration\n",
    "            for round_index in range(iteration_round_limit):\n",
    "\n",
    "                ## policy evaluation\n",
    "                rt = 3\n",
    "                score_gained = 0\n",
    "                score_max_turn = min(score_state-2, 3*fb.maxhitscore)\n",
    "                prob_turn_transit_nt = solve_turn_transit_probability_fast_nt(score_state, state_action, prob_grid_normalscore_nt, prob_grid_normalscore_t, prob_grid_doublescore_nt, prob_grid_doublescore_t, prob_grid_bullscore_nt, prob_grid_bullscore_t, prob_bust_dic_nt, prob_bust_dic_t)        \n",
    "                turn_transit_list[score_state].append(prob_turn_transit_nt.copy())\n",
    "                prob_turn_zeroscore = prob_turn_transit_nt['bust'] + prob_turn_transit_nt['score'][0]\n",
    "                #pzerolist.append(prob_turn_zeroscore)\n",
    "                new_value_rt3 = (1 + np.dot(prob_turn_transit_nt['score'][1:], optimal_value_rt3[0,score_state-1:score_state-score_max_turn-1:-1])) / (1-prob_turn_zeroscore)\n",
    "                state_value_update[rt][0][score_gained] = new_value_rt3\n",
    "                optimal_value_rt3[0,score_state] = new_value_rt3\n",
    "                #print('evaluate rt3 value= {}'.format(new_value_rt3)\n",
    "\n",
    "                ## policy improvement\n",
    "                for rt in [1,2,3]:            \n",
    "                    this_throw_state_len = state_len_vector[rt]\n",
    "                    \n",
    "                    ## state which can not bust.  score_state-score_gained>=62 \n",
    "                    state_notbust_len =  max(min(score_state-61, this_throw_state_len),0)\n",
    "                    if (state_notbust_len > 0):\n",
    "                        if (rt==1 and round_index==0):\n",
    "                            ## combine all non-bust states together \n",
    "                            state_notbust_update_index = state_notbust_len                    \n",
    "                            next_state_value_array = np.zeros((61, state_notbust_len))                    \n",
    "                            for score_gained in range(state_notbust_len):\n",
    "                                ## skip infeasible state\n",
    "                                if not fb.state_feasible_array[rt, score_gained]:\n",
    "                                    continue\n",
    "                                score_remain = score_state - score_gained\n",
    "                                score_max = 60 ## always 60 here\n",
    "                                score_max_plus1 = score_max + 1\n",
    "                                next_state_value_array[:,score_gained] = optimal_value_rt3[0,score_remain:score_remain-score_max_plus1:-1]\n",
    "                        elif (rt==2 and (round_index==0 or score_state<182)):\n",
    "                            ## combine all non-bust states together \n",
    "                            state_notbust_update_index = state_notbust_len\n",
    "                            next_state_value_array = np.zeros((61, state_notbust_len))                    \n",
    "                            for score_gained in range(state_notbust_len):\n",
    "                                ## skip infeasible state\n",
    "                                if not fb.state_feasible_array[rt, score_gained]:\n",
    "                                    continue\n",
    "                                score_remain = score_state - score_gained\n",
    "                                score_max = 60 ## always 60 here\n",
    "                                score_max_plus1 = score_max + 1\n",
    "                                next_state_value_array[:,score_gained] = state_value_update[rt-1][0][score_gained:score_gained+score_max_plus1]\n",
    "                        else: ##(rt==1 and round_index>0) or (rt==2 and round_index>0 and score_state>=182) or (rt==3)\n",
    "                            ## only update state of score_gained = 0\n",
    "                            state_notbust_update_index = 1\n",
    "                            next_state_value_array = np.zeros(61)\n",
    "                            score_gained = 0\n",
    "                            score_remain = score_state - score_gained\n",
    "                            score_max = 60 ## always 60 here\n",
    "                            score_max_plus1 = score_max + 1                    \n",
    "                            ## make a copy\n",
    "                            if (rt > 1):\n",
    "                                next_state_value_array[:] = state_value_update[rt-1][0][score_gained:score_gained+score_max_plus1]\n",
    "                            ## transit to next turn when rt=1\n",
    "                            else:\n",
    "                                next_state_value_array[:] = optimal_value_rt3[0,score_remain:score_remain-score_max_plus1:-1]\n",
    "\n",
    "                        ## matrix product to compute all together\n",
    "                        next_state_value_tensor = torch.from_numpy(next_state_value_array)\n",
    "                        ## transit to next throw in the same turn when rt=3,2\n",
    "                        ## -----------TOKEN LOGIC -------------\n",
    "                        if (rt > 1):                    \n",
    "                            num_turns_tensor = prob_normalscore_tensor_nt.matmul(next_state_value_tensor)\n",
    "                        ## transit to next turn when rt=1\n",
    "                        else:\n",
    "                            num_turns_tensor = 1 + prob_normalscore_tensor_nt.matmul(next_state_value_tensor)\n",
    "\n",
    "                        ## searching\n",
    "                        temp1 = num_turns_tensor.min(axis=0)                \n",
    "                        state_action_update[rt][0][0:state_notbust_update_index] = temp1.indices.numpy()\n",
    "                        state_value_update[rt][0][0:state_notbust_update_index] =  temp1.values.numpy()                \n",
    "                    \n",
    "                    ## state which possibly bust.  score_state-score_gained<62 \n",
    "                    if (state_notbust_len < this_throw_state_len):\n",
    "                        ## combine all bust states together \n",
    "                        state_bust_len = this_throw_state_len - state_notbust_len\n",
    "                        next_state_value_array = np.zeros((61, state_bust_len))\n",
    "                        for score_gained in range(state_notbust_len, this_throw_state_len):\n",
    "                            ## skip infeasible state\n",
    "                            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                                continue\n",
    "                            score_remain = score_state - score_gained\n",
    "                            #score_max = min(score_remain-2, 60)\n",
    "                            score_max = score_remain-2 ## less than 60 here\n",
    "                            score_max_plus1 = score_max + 1\n",
    "                            score_gained_index = score_gained - state_notbust_len ## index off set\n",
    "                            if (rt > 1):\n",
    "                                next_state_value_array[0:score_max_plus1,score_gained_index] = state_value_update[rt-1][0][score_gained:score_gained+score_max_plus1]\n",
    "                            ## transit to next turn when rt=1\n",
    "                            else:\n",
    "                                next_state_value_array[0:score_max_plus1,score_gained_index] = optimal_value_rt3[0,score_remain:score_remain-score_max_plus1:-1]\n",
    "                        \n",
    "                        next_state_value_tensor = torch.from_numpy(next_state_value_array)\n",
    "                        ## transit to next throw in the same turn when rt=3,2\n",
    "                        if (rt > 1):                    \n",
    "                            num_turns_tensor = prob_normalscore_tensor_nt.matmul(next_state_value_tensor)\n",
    "                        ## transit to next turn when rt=1\n",
    "                        else:\n",
    "                            num_turns_tensor = 1 + prob_normalscore_tensor_nt.matmul(next_state_value_tensor)                                                               \n",
    "\n",
    "                        ## consider bust/finishing for each bust state seperately \n",
    "                        num_turns_array = num_turns_tensor.numpy()                \n",
    "                        for score_gained in range(state_notbust_len, this_throw_state_len):\n",
    "                            ## skip infeasible state\n",
    "                            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                                continue\n",
    "                            score_remain = score_state - score_gained\n",
    "                            #score_max = min(score_remain-2, 60)\n",
    "                            score_max = score_remain-2 ## less than 60 here\n",
    "                            score_max_plus1 = score_max + 1\n",
    "                            score_gained_index = score_gained - state_notbust_len\n",
    "\n",
    "                            ## transit to the end of game\n",
    "                            if (rt > 1):\n",
    "                                if (score_remain == fb.score_DB):                        \n",
    "                                    num_turns_array[:,score_gained_index] += prob_DB_nt\n",
    "                                elif (score_remain <= 40 and score_remain%2==0):\n",
    "                                    num_turns_array[:,score_gained_index] += prob_doublescore_dic_nt[score_remain]\n",
    "                                else:\n",
    "                                    pass\n",
    "\n",
    "                            ## transit to bust\n",
    "                            if (rt==3):\n",
    "                                num_turns_array[:,score_gained_index] += prob_bust_dic_nt[score_max]\n",
    "                                ## solve an equation other than using the policy evaluation value (s,i=3,u=0)\n",
    "                                num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic_nt[score_max] \n",
    "                            elif (rt==2):\n",
    "                                num_turns_array[:,score_gained_index] += prob_bust_dic_nt[score_max]*(1+new_value_rt3)\n",
    "                            else:\n",
    "                                num_turns_array[:,score_gained_index] += prob_bust_dic_nt[score_max]*(new_value_rt3)  ## 1 turn is already counted before\n",
    "\n",
    "                        ## searching\n",
    "                        temp1 = num_turns_tensor.min(axis=0)\n",
    "                        state_action_update[rt][0][state_notbust_len:this_throw_state_len] = temp1.indices.numpy()\n",
    "                        state_value_update[rt][0][state_notbust_len:this_throw_state_len] =  temp1.values.numpy()                \n",
    "\n",
    "                    #### finish rt=1,2,3. check improvement\n",
    "                    action_diff[rt][0][:] = np.abs(state_action_update[rt][0] - state_action[rt][0])                                \n",
    "                    value_relerror[rt][0] = np.abs((state_value_update[rt][0] - state_value[rt][0])/state_value_update[rt][0]).max()\n",
    "                    state_action[rt][0][:] = state_action_update[rt][0][:]\n",
    "                    state_value[rt][0][:] = state_value_update[rt][0][:]\n",
    "\n",
    "                max_action_diff = max([action_diff[1].max(), action_diff[2].max(), action_diff[3].max()])\n",
    "                max_value_relerror = value_relerror.max()            \n",
    "                \n",
    "                if (max_action_diff < 1):\n",
    "                #if max_value_relerror < iteration_relerror_limit:\n",
    "                    num_iteration_record[score_state] = round_index + 1\n",
    "                    break\n",
    "\n",
    "            for rt in [1,2,3]:\n",
    "                state_value_update[rt][0][fb.state_infeasible[rt]] = fb.largenumber\n",
    "                state_action_update[rt][0][fb.state_infeasible[rt]] = fb.infeasible_marker\n",
    "            optimal_action_index_dic[score_state] = ft.copy_numberarray_container(state_action_update)\n",
    "            optimal_value_dic[score_state] = ft.copy_numberarray_container(state_value_update, new_dtype=fb.result_float_dytpe)\n",
    "            optimal_value_rt3[0,score_state] = state_value[3][0]\n",
    "            ## done:V(s,i=3/2/1,u)\n",
    "\n",
    "##\n",
    "prob_scorestate_transit = {}    \n",
    "prob_scorestate_transit =  solve_policy_transit_probability_nt(optimal_action_index_dic, prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore)\n",
    "t2 = time.time()\n",
    "print('solve dp_turn_policyiter in {} seconds'.format(t2-t1))\n",
    "\n",
    "print(optimal_value_rt3)\n",
    "result_dic = {'optimal_value_dic':optimal_value_dic, 'optimal_action_index_dic':optimal_action_index_dic, 'optimal_value_rt3':optimal_value_rt3, 'prob_scorestate_transit':prob_scorestate_transit}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0000035272854104"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_turn_transit_nt['bust'] \n",
    "#prob_turn_transit_nt['score'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1853716285565175"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_turn_zeroscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 0.0000e+00, 3.5273e-06, 3.4301e-01, 3.7475e-02, 3.4301e-01, 4.9629e-01, 4.9257e-01, 4.9257e-01, 3.2814e-01, 3.4347e-01, 4.0096e-01, 4.7810e-01, 5.7286e-01, 5.8664e-01, 4.9992e-01, 5.5814e-01, 6.0061e-01, 4.7832e-01, 5.1233e-01, 6.6667e-01, 6.6667e-01,        nan,        nan,\n",
       "              nan,        nan])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dic['optimal_value_rt3'][0][:26]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prob_turn_transit_nt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prob_turn_transit_nt[\u001b[39m'\u001b[39m\u001b[39mbust\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m prob_turn_transit_nt[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prob_turn_transit_nt' is not defined"
     ]
    }
   ],
   "source": [
    "prob_turn_transit_nt['bust'] + prob_turn_transit_nt['score'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check for Noturn Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachael/Desktop/OptimalDarts-main/function_solve_dp_tokens.py:174: RuntimeWarning: overflow encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n"
     ]
    }
   ],
   "source": [
    "[noturn_optimal_value, noturn_optimal_action_index] = fsdt.solve_dp_noturn_tokens(aiming_grid, prob_grid_normalscore_nt, prob_grid_normalscore_t, tokens = tokens, prob_grid_doublescore=prob_grid_doublescore_nt, prob_grid_bullscore=prob_grid_bullscore_nt,prob_grid_doublescore_t=prob_grid_doublescore_t, prob_grid_bullscore_t=prob_grid_bullscore_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([1., 1., 1., ..., 0., 0., 0.]),\n",
       " 1: array([0.9611, 0.7815, 0.7229, ..., 0.    , 0.    , 0.    ]),\n",
       " 2: array([0.9611, 0.7815, 0.7229, ..., 0.    , 0.    , 0.    ]),\n",
       " 3: array([0.9577, 0.7815, 0.7229, ..., 0.    , 0.    , 0.    ]),\n",
       " 4: array([0.9577, 0.7815, 0.7228, ..., 0.    , 0.    , 0.    ]),\n",
       " 5: array([0.8981, 0.5099, 0.4768, ..., 0.    , 0.    , 0.    ]),\n",
       " 6: array([0.8981, 0.5099, 0.4768, ..., 0.    , 0.    , 0.    ]),\n",
       " 7: array([0.8981, 0.5099, 0.4768, ..., 0.    , 0.    , 0.    ]),\n",
       " 8: array([0.8981, 0.5099, 0.4768, ..., 0.    , 0.    , 0.    ]),\n",
       " 9: array([0.8981, 0.5099, 0.476 , ..., 0.    , 0.    , 0.    ]),\n",
       " 10: array([0.8981, 0.5099, 0.476 , ..., 0.    , 0.    , 0.    ]),\n",
       " 11: array([0.8981, 0.5099, 0.476 , ..., 0.    , 0.    , 0.    ]),\n",
       " 12: array([0.898 , 0.5075, 0.443 , ..., 0.    , 0.    , 0.    ]),\n",
       " 13: array([0.898 , 0.5075, 0.443 , ..., 0.    , 0.    , 0.    ]),\n",
       " 14: array([0.898 , 0.5075, 0.4423, ..., 0.    , 0.    , 0.    ]),\n",
       " 15: array([0.898 , 0.5075, 0.4423, ..., 0.    , 0.    , 0.    ]),\n",
       " 16: array([0.898 , 0.5075, 0.4423, ..., 0.    , 0.    , 0.    ]),\n",
       " 17: array([0.898 , 0.5075, 0.4423, ..., 0.    , 0.    , 0.    ]),\n",
       " 18: array([0.898 , 0.5075, 0.4384, ..., 0.    , 0.    , 0.    ]),\n",
       " 19: array([0.898 , 0.5075, 0.4384, ..., 0.    , 0.    , 0.    ]),\n",
       " 20: array([6.6128e-03, 3.4573e-08, 7.1896e-04, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 21: array([6.6128e-03, 3.4573e-08, 7.1896e-04, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 22: array([6.6128e-03, 3.4573e-08, 7.1896e-04, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 23: array([6.6128e-03, 3.4573e-08, 7.1896e-04, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 24: array([6.6128e-03, 3.4573e-08, 7.1896e-04, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 25: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 26: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 27: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 28: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 29: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 30: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 31: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 32: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 33: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 34: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 35: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 36: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 37: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 38: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 39: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 40: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 41: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 42: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 43: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 44: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 45: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 46: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 47: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 48: array([6.6128e-03, 3.3859e-08, 3.0409e-12, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 49: array([6.6128e-03, 3.3859e-08, 1.8153e-07, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 50: array([6.6128e-03, 3.3859e-08, 3.0409e-12, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 51: array([6.6128e-03, 3.3859e-08, 3.0409e-12, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 52: array([6.6128e-03, 3.3859e-08, 3.0409e-12, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 53: array([6.6128e-03, 3.3859e-08, 3.0409e-12, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 54: array([6.6128e-03, 2.1545e-08, 1.1102e-16, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 55: array([6.6128e-03, 2.1545e-08, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 56: array([6.6128e-03, 2.1545e-08, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 57: array([6.6128e-03, 2.1545e-08, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 58: array([6.6128e-03, 2.1545e-08, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00]),\n",
       " 59: array([6.6128e-03, 2.1545e-08, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00, 0.0000e+00])}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_bust_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_turn_transit_probability_fast(score_state, state_action, prob_normalscore, prob_doublescore, prob_bullscore, prob_bust_dic):\n",
    "    \"\"\"\n",
    "    A fast way of implementing solve_turn_transit_probability by using pre-stored prob_bust_dic\n",
    "    \"\"\"     \n",
    "    \n",
    "    result_dict = {}\n",
    "    prob_finish = 0 ## probability of finishing the game\n",
    "    prob_bust_total = 0   ## probability of busting the game\n",
    "    ## initialize for (s, rt=3, score_gained=0)\n",
    "    next_throw_state_len = 1\n",
    "    prob_transit_next_throw_state = np.ones(next_throw_state_len)\n",
    "    \n",
    "    for rt in [3,2,1]:\n",
    "        prob_this_throw_state = prob_transit_next_throw_state\n",
    "        this_throw_state_len = next_throw_state_len\n",
    "        next_throw_state_len = min(score_state-2, fb.maxhitscore*(4-rt)) + 1\n",
    "        prob_transit_next_throw_state = np.zeros(next_throw_state_len)  ## probability vector of total score_gained after this throw\n",
    "        \n",
    "        prob_normalscore_transit = prob_normalscore[state_action[rt][0:this_throw_state_len]]*prob_this_throw_state.reshape((this_throw_state_len,1))\n",
    "        \n",
    "        for score_gained in range(this_throw_state_len):  # loop through score already gained\n",
    "            ## skip infeasible state\n",
    "            if not fb.state_feasible_array[rt, score_gained]:\n",
    "                continue   \n",
    "\n",
    "            ## aimming location of the policy at this state\n",
    "            aiming_location_index = state_action[rt][score_gained]\n",
    "            prob_this_state = prob_this_throw_state[score_gained]\n",
    "            \n",
    "            #largest possible normal socre to make in the next throw without busting\n",
    "            score_remain = score_state - score_gained\n",
    "            score_max = min(score_remain-2, 60)\n",
    "            score_max_plus1 = score_max + 1\n",
    "        \n",
    "            ## transit to next throw or turn with normal scores            \n",
    "            prob_transit_next_throw_state[score_gained:score_gained+score_max_plus1] += prob_normalscore_transit[score_gained, 0:score_max_plus1]\n",
    "            ## game can not bust or end when score_max = 60, i.e.,  prob_notbust = 1\n",
    "            if (score_max < 60):\n",
    "                ## transit to the end of game\n",
    "                if (score_remain == fb.score_DB):\n",
    "                    prob_finish += prob_bullscore[aiming_location_index, 1]*prob_this_state\n",
    "                elif (score_remain <= 40 and score_remain%2==0):\n",
    "                    doublescore_index = (score_remain//2) - 1\n",
    "                    prob_finish += prob_doublescore[aiming_location_index, doublescore_index]*prob_this_state\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                #transit to bust\n",
    "                prob_bust_total += prob_bust_dic[score_max][aiming_location_index]*prob_this_state\n",
    "            \n",
    "    result_dict['finish'] = prob_finish\n",
    "    result_dict['bust'] = prob_bust_total\n",
    "    result_dict['score'] = prob_transit_next_throw_state\n",
    "\n",
    "    return result_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachael/Desktop/OptimalDarts-main/function_solve_dp_tokens.py:82: RuntimeWarning: divide by zero encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n",
      "/Users/rachael/Desktop/OptimalDarts-main/function_solve_dp_tokens.py:82: RuntimeWarning: overflow encountered in divide\n",
      "  num_tothrow = num_tothrow / prob_otherstate\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/636321877.py:215: RuntimeWarning: divide by zero encountered in divide\n",
      "  num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic[score_max]\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/636321877.py:215: RuntimeWarning: overflow encountered in divide\n",
      "  num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic[score_max]\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/636321877.py:228: RuntimeWarning: divide by zero encountered in divide\n",
      "  value_relerror[rt] = np.abs((state_value_update[rt] - state_value[rt])/state_value_update[rt]).max()\n",
      "/var/folders/jj/jcq76kp53_zchkx8b5cvhdsh0000gn/T/ipykernel_48695/636321877.py:228: RuntimeWarning: invalid value encountered in divide\n",
      "  value_relerror[rt] = np.abs((state_value_update[rt] - state_value[rt])/state_value_update[rt]).max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solve prob_policy_transit in 0.24787569046020508 seconds\n",
      "solve dp_turn_policyiter in 1.7931010723114014 seconds\n",
      "[0.     0.     1.4381 ... 5.0818 5.0845 5.0965]\n"
     ]
    }
   ],
   "source": [
    "#pzerolist = []\n",
    "## aiming_grid\n",
    "num_aiming_location = aiming_grid.shape[0]\n",
    "prob_normalscore = prob_grid_normalscore\n",
    "prob_doublescore_dic = {}\n",
    "for doublescore_index in range(20):\n",
    "    doublescore = 2*(doublescore_index+1)\n",
    "    prob_doublescore_dic[doublescore] = np.array(prob_grid_doublescore[:,doublescore_index])\n",
    "prob_DB = np.array(prob_grid_bullscore[:,1])\n",
    "\n",
    "## the probability of not bust for each action given score_max=i (score_remain=i+2)\n",
    "prob_bust_dic = {}\n",
    "prob_notbust_dic = {}\n",
    "for score_max in range(60):    \n",
    "    ## transit to next throw or turn\n",
    "    prob_notbust = prob_grid_normalscore[:,0:score_max+1].sum(axis=1)\n",
    "    ## transit to the end of game\n",
    "    score_remain = score_max + 2\n",
    "    if (score_remain == fb.score_DB):\n",
    "        prob_notbust += prob_DB\n",
    "    elif (score_remain <= 40 and score_remain%2==0):\n",
    "        prob_notbust += prob_doublescore_dic[score_remain]\n",
    "    ##\n",
    "    prob_notbust = np.minimum(np.maximum(prob_notbust, 0),1)\n",
    "    prob_notbust_dic[score_max] = prob_notbust\n",
    "    prob_bust_dic[score_max] = 1 - prob_notbust_dic[score_max]\n",
    "\n",
    "prob_normalscore_tensor = torch.from_numpy(prob_normalscore)\n",
    "\n",
    "iteration_round_limit = 20\n",
    "iteration_relerror_limit = 10**-9\n",
    "\n",
    "#### state space example of (SB=25 DB=50) ####\n",
    "## rt: the number of remaining throws in a turn\n",
    "## state_infeasible_rt2 = [23, 29, 31, 35, 37, 41, 43, 44, 46, 47, 49, 52, 53, 55, 56, 58, 59]\n",
    "## state_infeasible_rt1 = [103, 106, 109, 112, 113, 115, 116, 118, 119]    \n",
    "    \n",
    "optimal_value_rt3 = np.zeros(502) #vector: optimal value for the beginning state of each turn (rt=3)\n",
    "optimal_value_dic = {} ## first key: score=0,2,...,501, second key: remaining throws=3,2,1\n",
    "optimal_action_index_dic = {}\n",
    "num_iteration_record = np.zeros(502, dtype=np.int32)\n",
    "\n",
    "state_len_vector = np.zeros(4, dtype=np.int32)\n",
    "state_value  = [None]  ## optimal value (expected # of turns to finish the game) for each state in the current playing turn\n",
    "state_action = [None]  ## aimming locations for for each state in the current playing turn\n",
    "action_diff  = [None]\n",
    "value_relerror = np.zeros(4)\n",
    "for rt in [1,2,3]:\n",
    "    ## for rt=3: possible score_gained = 0\n",
    "    ## for rt=2: possible score_gained = 0,1,...,60\n",
    "    ## for rt=1: possible score_gained = 0,1,...,120\n",
    "    this_throw_state_len = fb.maxhitscore*(3-rt) + 1\n",
    "    state_value.append(np.ones(this_throw_state_len)*fb.largenumber)\n",
    "    state_action.append(np.ones(this_throw_state_len, np.int32)*fb.infeasible_marker)\n",
    "    action_diff.append(np.ones(this_throw_state_len))\n",
    "state_value_update = ft.copy_numberarray_container(state_value)\n",
    "state_action_update = ft.copy_numberarray_container(state_action)\n",
    "\n",
    "## use no_turn policy as the initial policy\n",
    "[noturn_optimal_value, noturn_optimal_action_index] = fsdt.solve_dp_noturn(aiming_grid, prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore)\n",
    "\n",
    "t1 = time.time()\n",
    "for score_state in range(2, 502):\n",
    "    #print('#### solve_dp_turn score_state={} ####'.format(score_state))    \n",
    "    \n",
    "    ## initialization \n",
    "    for rt in [1,2,3]:\n",
    "        ## for rt=3: score_gained = 0\n",
    "        ## for rt=2: score_gained = 0,1,...,min(s-2,60)\n",
    "        ## for rt=1: score_gained = 0,1,...,min(s-2,120)\n",
    "        this_throw_state_len = min(score_state-2, fb.maxhitscore*(3-rt)) + 1\n",
    "        state_len_vector[rt] = this_throw_state_len\n",
    "                \n",
    "        ## initialize the starting policy: \n",
    "        ## use no_turn action in (s, i, u=0)\n",
    "        ## use turn action (s-1, i, u-1) in (s, i, u!=0) if (s-1, i, u-1) is feasible state\n",
    "        state_action[rt][0] = noturn_optimal_action_index[score_state]            \n",
    "        for score_gained in range(1,this_throw_state_len):                \n",
    "            if fb.state_feasible_array[rt, score_gained]:  ## if True\n",
    "                if fb.state_feasible_array[rt, score_gained-1]:\n",
    "                    state_action[rt][score_gained] = optimal_action_index_dic[score_state-1][rt][score_gained-1]\n",
    "                else:                        \n",
    "                    state_action[rt][score_gained] = noturn_optimal_action_index[score_state-score_gained]\n",
    "            else:\n",
    "                state_action[rt][score_gained] = fb.infeasible_marker\n",
    "\n",
    "    ## policy iteration\n",
    "    for round_index in range(iteration_round_limit):\n",
    "\n",
    "        ## policy evaluation\n",
    "        rt = 3\n",
    "        score_gained = 0\n",
    "        score_max_turn = min(score_state-2, 3*fb.maxhitscore)\n",
    "        prob_turn_transit = solve_turn_transit_probability_fast(score_state, state_action, prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore, prob_bust_dic)        \n",
    "        prob_turn_zeroscore = prob_turn_transit['bust'] + prob_turn_transit['score'][0]\n",
    "        #pzerolist.append(prob_turn_zeroscore)\n",
    "        new_value_rt3 = (1 + np.dot(prob_turn_transit['score'][1:], optimal_value_rt3[score_state-1:score_state-score_max_turn-1:-1])) / (1-prob_turn_zeroscore)\n",
    "        state_value_update[rt][score_gained] = new_value_rt3\n",
    "        optimal_value_rt3[score_state] = new_value_rt3\n",
    "        #print('evaluate rt3 value= {}'.format(new_value_rt3)\n",
    "\n",
    "        ## policy improvement\n",
    "        for rt in [1,2,3]:            \n",
    "            this_throw_state_len = state_len_vector[rt]\n",
    "            \n",
    "            ## state which can not bust.  score_state-score_gained>=62 \n",
    "            state_notbust_len =  max(min(score_state-61, this_throw_state_len),0)\n",
    "            if (state_notbust_len > 0):\n",
    "                if (rt==1 and round_index==0):\n",
    "                    ## combine all non-bust states together \n",
    "                    state_notbust_update_index = state_notbust_len                    \n",
    "                    next_state_value_array = np.zeros((61, state_notbust_len))                    \n",
    "                    for score_gained in range(state_notbust_len):\n",
    "                        ## skip infeasible state\n",
    "                        if not fb.state_feasible_array[rt, score_gained]:\n",
    "                            continue\n",
    "                        score_remain = score_state - score_gained\n",
    "                        score_max = 60 ## always 60 here\n",
    "                        score_max_plus1 = score_max + 1\n",
    "                        next_state_value_array[:,score_gained] = optimal_value_rt3[score_remain:score_remain-score_max_plus1:-1]\n",
    "                elif (rt==2 and (round_index==0 or score_state<182)):\n",
    "                    ## combine all non-bust states together \n",
    "                    state_notbust_update_index = state_notbust_len\n",
    "                    next_state_value_array = np.zeros((61, state_notbust_len))                    \n",
    "                    for score_gained in range(state_notbust_len):\n",
    "                        ## skip infeasible state\n",
    "                        if not fb.state_feasible_array[rt, score_gained]:\n",
    "                            continue\n",
    "                        score_remain = score_state - score_gained\n",
    "                        score_max = 60 ## always 60 here\n",
    "                        score_max_plus1 = score_max + 1\n",
    "                        next_state_value_array[:,score_gained] = state_value_update[rt-1][score_gained:score_gained+score_max_plus1]\n",
    "                else: ##(rt==1 and round_index>0) or (rt==2 and round_index>0 and score_state>=182) or (rt==3)\n",
    "                    ## only update state of score_gained = 0\n",
    "                    state_notbust_update_index = 1\n",
    "                    next_state_value_array = np.zeros(61)\n",
    "                    score_gained = 0\n",
    "                    score_remain = score_state - score_gained\n",
    "                    score_max = 60 ## always 60 here\n",
    "                    score_max_plus1 = score_max + 1                    \n",
    "                    ## make a copy\n",
    "                    if (rt > 1):\n",
    "                        next_state_value_array[:] = state_value_update[rt-1][score_gained:score_gained+score_max_plus1]\n",
    "                    ## transit to next turn when rt=1\n",
    "                    else:\n",
    "                        next_state_value_array[:] = optimal_value_rt3[score_remain:score_remain-score_max_plus1:-1]\n",
    "\n",
    "                ## matrix product to compute all together\n",
    "                next_state_value_tensor = torch.from_numpy(next_state_value_array)\n",
    "                ## transit to next throw in the same turn when rt=3,2\n",
    "                if (rt > 1):                    \n",
    "                    num_turns_tensor = prob_normalscore_tensor.matmul(next_state_value_tensor)\n",
    "                ## transit to next turn when rt=1\n",
    "                else:\n",
    "                    num_turns_tensor = 1 + prob_normalscore_tensor.matmul(next_state_value_tensor)\n",
    "\n",
    "                ## searching\n",
    "                temp1 = num_turns_tensor.min(axis=0)                \n",
    "                state_action_update[rt][0:state_notbust_update_index] = temp1.indices.numpy()\n",
    "                state_value_update[rt][0:state_notbust_update_index] =  temp1.values.numpy()                \n",
    "            \n",
    "            ## state which possibly bust.  score_state-score_gained<62 \n",
    "            if (state_notbust_len < this_throw_state_len):\n",
    "                ## combine all bust states together \n",
    "                state_bust_len = this_throw_state_len - state_notbust_len\n",
    "                next_state_value_array = np.zeros((61, state_bust_len))\n",
    "                for score_gained in range(state_notbust_len, this_throw_state_len):\n",
    "                    ## skip infeasible state\n",
    "                    if not fb.state_feasible_array[rt, score_gained]:\n",
    "                        continue\n",
    "                    score_remain = score_state - score_gained\n",
    "                    #score_max = min(score_remain-2, 60)\n",
    "                    score_max = score_remain-2 ## less than 60 here\n",
    "                    score_max_plus1 = score_max + 1\n",
    "                    score_gained_index = score_gained - state_notbust_len ## index off set\n",
    "                    if (rt > 1):\n",
    "                        next_state_value_array[0:score_max_plus1,score_gained_index] = state_value_update[rt-1][score_gained:score_gained+score_max_plus1]\n",
    "                    ## transit to next turn when rt=1\n",
    "                    else:\n",
    "                        next_state_value_array[0:score_max_plus1,score_gained_index] = optimal_value_rt3[score_remain:score_remain-score_max_plus1:-1]\n",
    "                \n",
    "                next_state_value_tensor = torch.from_numpy(next_state_value_array)\n",
    "                ## transit to next throw in the same turn when rt=3,2\n",
    "                if (rt > 1):                    \n",
    "                    num_turns_tensor = prob_normalscore_tensor.matmul(next_state_value_tensor)\n",
    "                ## transit to next turn when rt=1\n",
    "                else:\n",
    "                    num_turns_tensor = 1 + prob_normalscore_tensor.matmul(next_state_value_tensor)                                                               \n",
    "\n",
    "                ## consider bust/finishing for each bust state seperately \n",
    "                num_turns_array = num_turns_tensor.numpy()                \n",
    "                for score_gained in range(state_notbust_len, this_throw_state_len):\n",
    "                    ## skip infeasible state\n",
    "                    if not fb.state_feasible_array[rt, score_gained]:\n",
    "                        continue\n",
    "                    score_remain = score_state - score_gained\n",
    "                    #score_max = min(score_remain-2, 60)\n",
    "                    score_max = score_remain-2 ## less than 60 here\n",
    "                    score_max_plus1 = score_max + 1\n",
    "                    score_gained_index = score_gained - state_notbust_len\n",
    "\n",
    "                    ## transit to the end of game\n",
    "                    if (rt > 1):\n",
    "                        if (score_remain == fb.score_DB):                        \n",
    "                            num_turns_array[:,score_gained_index] += prob_DB\n",
    "                        elif (score_remain <= 40 and score_remain%2==0):\n",
    "                            num_turns_array[:,score_gained_index] += prob_doublescore_dic[score_remain]\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                    ## transit to bust\n",
    "                    if (rt==3):\n",
    "                        num_turns_array[:,score_gained_index] += prob_bust_dic[score_max]\n",
    "                        ## solve an equation other than using the policy evaluation value (s,i=3,u=0)\n",
    "                        num_turns_array[:,score_gained_index] = num_turns_array[:,score_gained_index] / prob_notbust_dic[score_max] \n",
    "                    elif (rt==2):\n",
    "                        num_turns_array[:,score_gained_index] += prob_bust_dic[score_max]*(1+new_value_rt3)\n",
    "                    else:\n",
    "                        num_turns_array[:,score_gained_index] += prob_bust_dic[score_max]*(new_value_rt3)  ## 1 turn is already counted before\n",
    "\n",
    "                ## searching\n",
    "                temp1 = num_turns_tensor.min(axis=0)\n",
    "                state_action_update[rt][state_notbust_len:this_throw_state_len] = temp1.indices.numpy()\n",
    "                state_value_update[rt][state_notbust_len:this_throw_state_len] =  temp1.values.numpy()                \n",
    "\n",
    "            #### finish rt=1,2,3. check improvement\n",
    "            action_diff[rt][:] = np.abs(state_action_update[rt] - state_action[rt])                                \n",
    "            value_relerror[rt] = np.abs((state_value_update[rt] - state_value[rt])/state_value_update[rt]).max()\n",
    "            state_action[rt][:] = state_action_update[rt][:]\n",
    "            state_value[rt][:] = state_value_update[rt][:]\n",
    "\n",
    "        max_action_diff = max([action_diff[1].max(), action_diff[2].max(), action_diff[3].max()])\n",
    "        max_value_relerror = value_relerror.max()            \n",
    "        \n",
    "        if (max_action_diff < 1):\n",
    "        #if max_value_relerror < iteration_relerror_limit:\n",
    "            num_iteration_record[score_state] = round_index + 1\n",
    "            break\n",
    "\n",
    "    for rt in [1,2,3]:\n",
    "        state_value_update[rt][fb.state_infeasible[rt]] = fb.largenumber\n",
    "        state_action_update[rt][fb.state_infeasible[rt]] = fb.infeasible_marker\n",
    "    optimal_action_index_dic[score_state] = ft.copy_numberarray_container(state_action_update)\n",
    "    optimal_value_dic[score_state] = ft.copy_numberarray_container(state_value_update, new_dtype=fb.result_float_dytpe)\n",
    "    optimal_value_rt3[score_state] = state_value[3][0]\n",
    "    ## done:V(s,i=3/2/1,u)\n",
    "\n",
    "##\n",
    "prob_scorestate_transit = {}    \n",
    "prob_scorestate_transit =  fep.solve_policy_transit_probability(optimal_action_index_dic, prob_grid_normalscore, prob_grid_doublescore, prob_grid_bullscore)\n",
    "t2 = time.time()\n",
    "print('solve dp_turn_policyiter in {} seconds'.format(t2-t1))\n",
    "\n",
    "print(optimal_value_rt3)\n",
    "result_dic = {'optimal_value_dic':optimal_value_dic, 'optimal_action_index_dic':optimal_action_index_dic, 'optimal_value_rt3':optimal_value_rt3, 'prob_scorestate_transit':prob_scorestate_transit}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9934, 1.    , 1.    , ..., 1.    , 1.    , 1.    ])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_notbust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8a57194bbeb03cec992a62989c4918360c5f4e4ce600e16b9e817797d129cef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
